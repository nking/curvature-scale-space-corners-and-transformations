- fix the canny adaptive line thinning.  it looks like the wrong
  direction is sometimes used.
- several algorithms need repair after changes in classes they use

-- add and thoroughly test new errors method for HOGS
   -- add visualization of the HOG orientations
   -- impl the new comparison score
   -- improve or make a new HOGS object matcher (keep MSER)
   -- 

-- for the android statues matching,
   next consider steps:
    - find the mser regions to compare
    - use convolutional neural networks for the matching
      after considering how to use HOGs and invariance
      of transformations...
-- 
  https://github.com/mnielsen/neural-networks-and-deep-learning.git

-- also, review some of the architectures for 
   hashing, that is compare pros and cons compared to
   open addressing for example

-- additional reading on convolution networks, and look for
   any that are using monogenic filters to improve the runtime complexity.
   http://arxiv.org/abs/1311.2901

-- after next round of object matching improvements,
    consider datasets from benchmark challenge:
    https://en.wikipedia.org/wiki/ImageNet_Large_Scale_Visual_Recognition_Challenge
    mentioned in:
        https://en.wikipedia.org/wiki/Convolutional_neural_network
        where there is brief discussion of difficulties in
        object recognition

-- to explore current market parts, make 2 computers from
   scratch using stores like Fry's and NewEgg
   - (1) an economy model like I always get
   - (2) a high end model with large amount of memory using the ram that
         doesn't overheat (more expensive)
         and large amount of storage.
         -- look into ideal number and kinds of L1 and L2 caches for the
            architecture.
         -- monitors
-- Neural networks:
   -- optimization:
      http://neuralnetworksanddeeplearning.com/chap3.html
      https://github.com/jaberg/hyperopt
      (Bergstra and Bengio 2012)

   -- alternative to minimize cost function instead of stochastic
      gradient descent is LBFGS.


-- revist the event server search :
    -- there should be more modenr datasets to use
        and should be able to choose other than
        the perceptron.
        -- some of the loading of data could be imrpved too
-- do exercises for Fig 4.11, pg 220 of Bishop 2006
-- http://www.gaussianprocess.org/gpml/code/matlab/doc/
   and tensorflow
     https://github.com/NervanaSystems/neon
     https://en.wikipedia.org/wiki/Theano_(software)
     https://en.wikipedia.org/wiki/Torch_(machine_learning)

-- impl iterative reweighted least squares


-- for the smoothing of the separation curve,
   could retry knn, that is use same pyramidal,
   but without re-sampling AND divide each range
   by h to include volume, making the curve density.
     see bishop 2006, chap 2.5

-- update the documentation on the shared and two-point-correlation
   sites.
   -- add to the two-point-correl a todo to improvements for dataset size
      and as always, fitting for cluster association.
      holding off on some of that because adding dimensional ability will
      change how these are done.
   -- since voronoi is N log N, might be interesting to look at some of the
      metrics.   the kNN is already doing so, so could 
        use it to explore

 (1) reading bishop 2006
    and looking at
    http://www.gaussianprocess.org/gpml/code/matlab/doc/
    and tensorflow
    -- Conditional Random Fields
    -- variational Bayes and expectation propagation

(2) read the remote sensing paper

-- consider making a greyscale MSEREdges

-- when return to improving the segmentation, run MSEREdges on
     the berkeley benchmark data

-- consider implementing a affine transformation class

-- consider implementing a 3-view transformation solver
   ...trifocal tensor

-- finish the new HOGs comparison method

-- interesting:
   solving the transformations between 2 images
   when have most of the camera matrix except focal length.

   http://www.vis.uky.edu/~stewe/publications/stewenius_05_cvpr_focal.pdf

   for Structure in Motion, camera information is needed and 5 points of
      correspondence.
   When camera infor is not available, epipolar geometry w/ 7 points of
      correspondence is used, but is not as stable.

   also see
       P. Sturm, On Focal Length Calibration from Two Views,
       IEEE International Conference on Computer Vision and Pattern
       Recognition, Volume 2, pp. 145â€“150, 2001
 
-- geohashing and bag of words, etc

-- consider implementing Paris and Durand 2007
     -- uses kruskal's mst for merging os is a fast NlogN

-- consider implementing one day, compressed histogram of grdients:
http://web.stanford.edu/~bgirod/pdfs/Chandrasekhar_CVPR2009.pdf

-- low priority: improve the auxillary methods in the partial shape matchers
    to calculate cost when given correspondence.

-- add use of YFastTrie to the min heap class w/ a check for 
     memory available.

-- consider implementing Tarjans latest paper (bipartite matching)

-- consider implementing vanishing lines based upon MSER ellipses

-- consider making a version of normalized cuts that uses the spatial location
    of points too (lkeeping labeled regions contiguous)

-- consider implementing a mean shift algorithm

-- fix the ransac iterator estimate that has a limit of
    (1790?)

-- read more on "Simultaneous Localization and Mapping, or SLAM"
     
-- consider following the implementation of disparity maps for stereo images
   and 3d modelling.  see notes in the docs directory.
   -- see http://vision.middlebury.edu/stereo/code/

-- test for degenerate camera conditions:
   -- parallel camera motion w/o rotation 
-- test for degenerate scene structure configurations
   -- all points lying on a plane or nearly lying on a plane (?)
-- test for point sets containing noise

-- more reading on 3d reconstruction
   and http://www.cs.cornell.edu/~snavely/projects/skeletalset/SkeletalSets_cvpr08.pdf

-- finish the special topics reading
   -- add to it "Mastering the game of Go with 
      deep neural networks and tree search"
      which is reinforcement learning in ML
2  --  https://openproceedings.org/2016/conf/edbt/paper-54.pdf
   -- https://link.springer.com/chapter/10.1007%2F978-3-642-21887-3_28?LI=true
   -- the go game playing paper referenced in quantum_notes.txt, espec. compared
          to gobmk

-- priority is implement when needed:
   considering algorithms to implement:
   0: looking at bayesian optimization
   1: hybrid global search
      considering these
          -- scatter
              https://www.researchgate.net/publication/228011098_The_Scatter_Search_Methodology
          -- tabu
              http://www.iro.umontreal.ca/~dift6751/paper_glover_ts_2.pdf
          -- pso
             https://github.com/CAChemE/stochastic-optimization
   2: Metropolis:
         http://introcs.cs.princeton.edu/java/98simulation/Metropolis.java.html
      http://introcs.cs.princeton.edu/java/98simulation/MarkovChain.java.html
      http://web.engr.illinois.edu/~bkclark/PIMCTutorial/tutorial.pdf
        https://arxiv.org/pdf/quant-ph/9607014.pdf
      -- importance sampling
         http://jrxv.net/x/16/ism.pdf

-- no priority:
   for jni bindings of the c++ dlib library, would like to automate
    the steps of compile, outlined by the MITIE project.
    dependencies (but for automated platform independence):
      -- swig:
         swig is platform specific and depends upon another platform 
           specific library called PCRE (needed to make pearl bindings).
         to automate the installation if needed and then the use of swig
            to compiJle, a possibility is the use of 2 maven2 plugins:
               -- freehep-swig-plugin 
               -- freehep-nar-plugin 
            the swig plugin requires some additional configuration for
            the download and there is only a small amount of documentation 
            on that.
            -- missing is the information that PCRE needs to be downloaded
               also so that would need to be added to the configuration
               if possible.
            A caveat to this is that these numerous steps to a mvn target
              checking for swig and dependencies and installing them with
              nar when needed would have to be tested for all platforms.
      -- nar:
            writing the nar commands to use swig and cmake would have to
            include the platform specific details present in the
            MITIE README.md file, espec for windows.
            this builds archive files so would be an offline step to
            provide os specific dependencies (which can do if convert 
            project to maven build system)
     cannot easily test on all platforms at this time, so will leave this
     as a todo target for the interesting details, but essentially no
G
     expected priority.
