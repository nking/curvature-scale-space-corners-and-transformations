<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>two-point-correlation by nking</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">two-point-correlation</h1>
      <h2 class="project-tagline">Unsupervised Density Based Clustering</h2>
      <a href="https://github.com/nking/two-point-correlation" class="btn">View on GitHub</a>
      <a href="https://github.com/nking/two-point-correlation/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/nking/two-point-correlation/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p><img src="images/snapshot.001.png" width="250" height="250"> <img src="images/snapshot.002.png" width="250" height="250"> <img src="images/snapshot.004.png" width="250" height="250"></p>

<p>The code is a <b>density based clustering algorithm</b>. The algorithm does not require prior knowledge of the number of clusters, nor does it require a separation distance for association of points, and the algorithm finds non-convex cluster shapes in a statistically based manner that is reproducable. The algorithm learns the association separation distance of points by the statistics of the data itself and applies that in a critical threshold for membership of points within a cluster.</p>

<p>The algorithm, in an unsupervised manner, constructs a distance transform for every non-point relative to the nearest point in the dataset.  Histograms are formed from the inverse square root of the distance transform and the first peaks in the histogram are fit to derive the critical density.  The critical separation between 2 points is then calculated from the critical density and a factor above background.  Any points closer to one another than the critical separation are within clustering distance of one another.</p>

<p>The results are available as data and visualized through generated html plots. (Improvements to packaging and documentation are in progress.)</p>

<p>More about the density distribution:</p>

<p>Usage as an API:</p>

<pre>
    To use the code with default settings:

    DTClusterFinder clusterFinder = new DTClusterFinder(points,
        imageWidth, imageHeight);

    clusterFinder.setToDebug();

    clusterFinder.calculateCriticalDensity();

    // alternatively, if the density is known, set instead of calculate:
    //clusterFinder.setCriticalDensity(dens);

    clusterFinder.findClusters();

    int nGroups = clusterFinder.getNumberOfClusters();

    List<Set<PairInt>> groupList = new ArrayList<Set<PairInt>>();
    for (int k = 0; k < nGroups; ++k) {
        Set<PairInt> set = clusterFinder.getCluster(k);
        groupList.add(set);
    }
</pre>

<p>The scatter plots and histograms below use <a href="http://d3js.org">d3 js</a></p>

<hr>

<blockquote>
<p>The citation for use of this code in a publication is:</p>

<p><code>http://code.google.com/p/two-point-correlation/</code>, Nichole King,  "Unsupervised Clustering Based Upon Voids in Two-Point Correlation". March 15, 2013. </p>
</blockquote>

<p>The previous version of this code is presented in the <a href="gev.html">previous web page</a>.

<p>Note that I wrote the core algorithm in this work (without the automated density calculation) several years ago and the results were part of a publication.
What got published was the results from this algorithm used as input for another algorithm that requires 
knowledge of association radius in order to work.   The algorithm that used my algorithm's input required a parameter that was not derivable from it's use alone.
Similarly, "k-means clustering" requires knowledge of the number of clusters before use.  "k-means++" is an algorithm that suggests one can adjust the number of clusters k, but a statistical method of doing so would still require a density based analysis, and hence, it would need to do the same work as the algorithm here, but presumably less efficiently.  Delaunay Triangulation is useful if there are no background points within a dataset, that is all points will be members of a group, and if groups do not have non-convex shapes.  KDTrees are useful as a nearest neighbor algorithm, but its use in determining clusters would still require as input, an association radius.
Fun stuff, but the core of the algorithm here is was what I needed to create awhile back for work applied to galaxy surveys.  The addition published here is automation of the background determination and large improvements of the
overall algorithm. </p>

<hr>

<h2>
<a id="non-convex-morphology-clusters" class="anchor" href="#non-convex-morphology-clusters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Non-Convex Morphology Clusters</h2>

<!--
<p><img src="images/wikipedia_dbscan.png"></p>
-->

<p>The cluster "shape" datasets collected at <a href="http://cs.joensuu.fi/sipu/datasets/">http://cs.joensuu.fi/sipu/datasets/</a> are fit here with explanations of code settings used and comments about the data.</p>

<p>These clusters were found with the default algorithm settings.  No additional settings were needed for the background:</p>
<img src="images/snapshot_shapes_01_dt.png" width="300">
<img src="images/snapshot_shapes_02_dt.png" width="300">
<img src="images/snapshot_shapes_03_dt.png" width="300">
<img src="images/snapshot_shapes_04_dt.png" width="300">
<img src="images/snapshot_shapes_05_dt.png" width="300">
<img src="images/snapshot_shapes_06_dt.png" width="300">
<img src="images/snapshot_shapes_07_dt.png" width="300">
<img src="images/snapshot_shapes_08_dt.png" width="300">

<hr>

<h2>
<a id="performance-metrics" class="anchor" href="#performance-metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Performance Metrics</h2>

<blockquote>
<p>The runtime complexity is roughly O(N<sub>pixels</sub> X log<sub>2</sub>(N<sub>pixels</sub>)) where N<sub>pixels</sub> is the width times height of the image.
The space complexity is roughly platform word size X width X height, so for a width of 5000 and height of 5000, the code must be run with java arguments to increase the stack size or the data must be reduced in size... like knapsack, the code is using dynamic programmining using arrays that are as long as needed for capacity.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/nking/two-point-correlation">two-point-correlation</a> is maintained by <a href="https://github.com/nking">nking</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>
  
  </body>
</html>
