<!DOCTYPE html>
<html lang="en-us">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-11146214-6"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-11146214-6');
    </script>

    <meta charset="UTF-8">
    <title>Curvature-scale-space-corners-and-transformations by nking</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <meta name="keywords" content="software, computer vision, Climb With Your Feet" />
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="favicon.ico" />
    <meta name="description" content="Computer Vision software that started with curvature scale space" />

  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Curvature-scale-space-corners-and-transformations</h1>
      <h2 class="project-tagline">Machine Learning and Computer Vision Programs</h2>
      <a href="https://github.com/nking/curvature-scale-space-corners-and-transformations" class="btn">View on GitHub</a>
      <a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>This holds a few summary notes and snapshots.</p>

<p>Machine Learning:</p>
        <ul>
            <li> Object detection with the
                <a href="https://paperswithcode.com/method/ssd">(SSD)</a>
                single-stage object detection algorithm.
                Using transfer-learning from a pre-trained SSD model and re-fitting the
                classifier using android lawn statue images
                while retaining (not re-training) the detection head weights
                learned from the COCO dataset, the android statues are identified in
                video frames from a YouTube video.
                <table>
                    <tr>
                        <td>
                            <a href="https://raw.githubusercontent.com/nking/curvature-scale-space-corners-and-transformations/master/src/duckies_and_statues,_interactive_eager_few_shot_obj_det_training_colab.ipynb">The colab notebook.</a>
                        </td>
                        <td>
                            <a href="images/android_statues_obj_det_ssd_07.png">
                                <img alt="snapshots of object detection with android lawn statues"
                                     src="images/android_statues_obj_det_ssd_07.png"
                                     width="30" height="30"/>
                            </a>
                        </td>
                        <td>
                            <a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/raw/master/doc/statues_transfer_learning_object_detection.pdf">Summary snapshots and statistics.</a>
                        </td>
                    </tr>
                </table>
            </li>
            <!-- add the multiclass classification notes
            <li>
            </li>
            -->
            <!-- add the transformer notes
            <li>
            </li>
            -->
        </ul>

<p>Highlights of computer vision algorithms (without machine learning):</p>
    <ul>
        <li> Finding an object in a segmented image by shape alone (ShapeFinder2.java)
             has the true solution in the top matches, but not necessarily the top match,
             and is more computationally expensive than other methods listed.
            <table>
            <tr>
            <td>
            <a href="images/shape_matcher.png">
            <img alt="snapshots of shape matching results"
                src="images/shape_matcher.png"
                width="30" height="30"/>
            </a>
            </td>
            </tr>
            </table>
        </li>
        <li>
             A correspondence list can be made quickly with 
             keypoints (e.g. Harris corners, inflection points, peaks in aTrous wavelets) and
             the rotationally invariant ORB descriptors.  RANSAC is also used to further remove outliers
             through epipolar fits.
            <table>
            <tr>
            <td>
            <a href="images/image_correspondence.png">
            <img alt="snapshots of image correspondence"
                src="images/image_correspondence.png"
                width="30" height="30"/>
            </a>
            </td>
            </tr>
            </table>
        </li>
        <li>
             An improved Canny Edges Filter can be made for color images by combining the greyscale
             Canny edges with the same made with the "C" image of the LCH colorspace.
            <table>
            <tr>
            <td>
            <a href="images/canny_color_edges.png">
            <img alt="Canny edges using color"
                src="images/canny_color_edges.png"
                width="30" height="30"/>
            </a>
            </td>
            </tr>
            </table>
        </li>
        <li>
            MSER (Maximally Stable Extremal Regions) are a very fast algorithm that can be used
            where level sets are needed.  Using MSER on greyscale and on the "H" image of
            LCH color space can find potential objects.  
            I combined the Canny color edges with the boundaries of MSER regions to create
            edges that are complete contours (== segmentation).
            The current version has some color filter rules that are potentially fragile and
            the use of MSER is resolution dependent so a wrapper class is provided.
            The results look promising.
            <table>
            <tr>
            <td>
            <a href="images/seattle_edges.png">
            <img alt="MSEREdges run on image of Seattle"
                src="images/seattle_edges.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/andr_01_edges.png">
            <img alt="MSEREdges run on image of android statues"
                src="images/andr_01_edges.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/andr_03_edges.png">
            <img alt="MSEREdges run on image of android statues"
                src="images/andr_03_edges.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/checkerboard_edges.png">
            <img alt="MSEREdges run on image of checkerboard"
                src="images/checkerboard_edges.png"
                width="30" height="30"/>
            </a>
            </td>
            </tr>
            </table>
        </li>
        <li>
            Finding an object in another image in which it has changed location, lighting,
            and pose is not easy, but can be done with MSER and HOGs.
            The current version has wrapper classes which help pre-prepare the images.
            <table>
            <tr>
            <td>
            <a href="images/gingerbreadman_corres.png">
            <img alt="image of android statues showing gingerbreadman match"
                src="images/gingerbreadman_corres.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/icecream_corres.png">
            <img alt="image of android statues showing icecream match"
                src="images/icecream_corres.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/cupcake_corres.png">
            <img alt="image of android statues showing cupcake match"
                src="images/cupcake_corres.png"
                width="30" height="30"/>
            </a>
            </td>
            <td>
            <a href="images/honeycomb_corres.png">
            <img alt="image of android statues showing honeycomb match"
                src="images/honeycomb_corres.png"
                width="30" height="30"/>
            </a>
            </td>
            </tr>
            </table>
        </li>
    </ul>

<p>Some of the notes while implementing comp vis w/o machine learning:</p>

<p><a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/raw/master/doc/colorSegmentation3.pdf">segmentation and edges</a></p>

<p><a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/raw/master/doc/contours.pdf">misc scale space contour notes</a></p>

<p><a href="https://github.com/nking/curvature-scale-space-corners-and-transformations/raw/master/doc/projection.pdf">projection</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/nking/curvature-scale-space-corners-and-transformations">Curvature-scale-space-corners-and-transformations</a> is maintained by <a href="https://github.com/nking">nking</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
