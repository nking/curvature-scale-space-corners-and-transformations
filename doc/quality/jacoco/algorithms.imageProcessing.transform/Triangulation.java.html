<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Triangulation.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Jacoco Report</a> &gt; <a href="index.source.html" class="el_package">algorithms.imageProcessing.transform</a> &gt; <span class="el_source">Triangulation.java</span></div><h1>Triangulation.java</h1><pre class="source lang-java linenums">package algorithms.imageProcessing.transform;

import algorithms.imageProcessing.transform.Camera.CameraParameters;
import algorithms.imageProcessing.transform.Camera.CameraProjection;
import algorithms.matrix.MatrixUtil;

import java.util.Arrays;
import java.util.logging.Level;
import java.util.logging.Logger;
import no.uib.cipr.matrix.DenseMatrix;
import no.uib.cipr.matrix.NotConvergedException;
import no.uib.cipr.matrix.SVD;
import java.util.Map;
import java.util.List;

/**
 * given correspondence between two images (in camera reference frame, a.k.a. calibrated coordinates)
 * and given the intrinsic and extrinsic camera
 * parameters, determine the real world position.
 * 
 * useful reading:
 * &lt;pre&gt;
 * http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
 * add other references here
 * &lt;/pre&gt;
 *
 * @author nichole
 */
<span class="pc" id="L29">public class Triangulation {</span>

    public static class WCSPt {
        /**
         * real world coordinate of the observation.  [4X1]
         */
        public double[] X;

        /**
         * a scale factor between x and X: x = alpha * P * X
         * where P = K * R * [I | -t];
         * the term 1/alpha is sometimes used as lambda, the multiple of x instead.
         */
        public double alpha;

    }

    /**
     * given the intrinsic and extrinsic camera matrices for 2 images
     * and given the matching correspondence of points between the 2 images (in camera reference frame)
     * where the correspondence are observations
     * of the same object,
     * calculate the real world coordinate of the object.
     * 
     * &lt;pre&gt;
     * following http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
     * &lt;/pre&gt;
     * @param k1 intrinsic camera matrix for image 1 in units of pixels.
     * @param r1 the rotation matrix for the extrinsic camera matrix for image 1.
     * @param t1 the translation vector for the extrinsic camera matrix for image 1.
     * @param k2 intrinsic camera matrix for image 2 in units of pixels.
     * @param r2 the rotation matrix for the extrinsic camera matrix for image 2.
     * @param t2 the translation vector for the extrinsic camera matrix for image 2.
     * @param x1 the camera 1 set of correspondence points.  format is 3 x N where
     * N is the number of points.  all points are observations of real world point X
     *           and should be in image reference frame.
     * @param x2 the camera 2 set of correspondence points.  format is 3 x N where
     *      * N is the number of points.  all points are observations of real world point X
     *      *           and should be in image reference frame.
     * @return the point coordinates in world coordinate reference frame
     */
    public static WCSPt calculateWCSPoint(
            double[][] k1, double[][] r1, double[] t1,
            double[][] k2, double[][] r2, double[] t2,
            double[][] x1, double[][] x2) {
        
<span class="pc bpc" id="L75" title="2 of 4 branches missed.">        if (k1.length != 3 || k1[0].length != 3) {</span>
<span class="nc" id="L76">            throw new IllegalArgumentException(&quot;k1 must be 3 x 3&quot;);</span>
        }
<span class="pc bpc" id="L78" title="2 of 4 branches missed.">        if (k2.length != 3 || k2[0].length != 3) {</span>
<span class="nc" id="L79">            throw new IllegalArgumentException(&quot;k2 must be 3 x 3&quot;);</span>
        }
<span class="pc bpc" id="L81" title="2 of 4 branches missed.">        if (r1.length != 3 || r1[0].length != 3) {</span>
<span class="nc" id="L82">            throw new IllegalArgumentException(&quot;r1 must be 3 x 3&quot;);</span>
        }
<span class="pc bpc" id="L84" title="2 of 4 branches missed.">        if (r2.length != 3 || r2[0].length != 3) {</span>
<span class="nc" id="L85">            throw new IllegalArgumentException(&quot;r2 must be 3 x 3&quot;);</span>
        }
<span class="pc bpc" id="L87" title="1 of 2 branches missed.">        if (t1.length != 3 ) {</span>
<span class="nc" id="L88">            throw new IllegalArgumentException(&quot;t1 must be length 3&quot;);</span>
        }
<span class="pc bpc" id="L90" title="1 of 2 branches missed.">        if (t2.length != 3 ) {</span>
<span class="nc" id="L91">            throw new IllegalArgumentException(&quot;t2 must be length 3&quot;);</span>
        }
<span class="pc bpc" id="L93" title="2 of 4 branches missed.">        if (x1.length != 3 || x2.length != 3) {</span>
<span class="nc" id="L94">            throw new IllegalArgumentException(&quot;x1.length must be 3 and so must x2.length&quot;);</span>
        }
<span class="fc" id="L96">        int n = x1[0].length;</span>
<span class="pc bpc" id="L97" title="1 of 2 branches missed.">        if (x2[0].length != n) {</span>
<span class="nc" id="L98">            throw new IllegalArgumentException(&quot;x1 and x2 must be same dimensions&quot;);</span>
        }

        // 3 x 4
<span class="fc" id="L102">        double[][] camera1 = Camera.createCamera(k1, r1, t1);</span>
        
<span class="fc" id="L104">        double[][] camera2 = Camera.createCamera(k2, r2, t2);</span>
        
<span class="fc" id="L106">        return calculateWCSPoint(camera1, camera2, x1, x2);</span>
    }

    /**
     * given the projection matrices and matching correspondence of points between the 2 cameras
     * (measurements of the same object, that is, as a single 3D point is returned) calculate the real world
     * coordinate of the observations.

     x1, y1 must be in image reference frame for this method.
     &lt;pre&gt;

     following http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
     &lt;/pre&gt;
     * @param camera1 camera parameters for image 1.   the size is 3X4
     *
     * @param camera2 camera parameters for image 2. the size is 3X4.
     *
     * @param x1 the set of measurements of 1 real world point X from camera 1 in image coordinates.
     * The corresponding measurements of the same point in camera 2 are in x2.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @param x2 the set of measurements of 1 real world point X from camera 2 in image coordinates.
     * The corresponding measurements of the same point in camera 1 are in x1.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @return the 3D coordinate of the point in world scene.  note that
     * the entire array can be normalized by the last element.
     */
    public static WCSPt calculateWCSPoint(
        CameraParameters camera1, CameraParameters camera2,
        double[][] x1, double[][] x2) {
        
<span class="nc" id="L140">        return calculateWCSPoint(camera1.getIntrinsicParameters().getIntrinsic(),</span>
<span class="nc" id="L141">            camera1.getExtrinsicParameters().getRotation(),</span>
<span class="nc" id="L142">            camera1.getExtrinsicParameters().getTranslation(),</span>
<span class="nc" id="L143">            camera2.getIntrinsicParameters().getIntrinsic(),</span>
<span class="nc" id="L144">            camera2.getExtrinsicParameters().getRotation(),</span>
<span class="nc" id="L145">            camera2.getExtrinsicParameters().getTranslation(),</span>
            x1, x2);
    }

    /**
     * given the projection matrices and matching correspondence of points between the 2 cameras
     * (measurements of the same object, that is, as a single 3D point is returned) calculate the real world
     * coordinate of the observations.
     *
     &lt;pre&gt;
     if x1 and x2 are in camera coordinates, then Pi = [Ri | Ti] must be used.
     if x1 and x2 are in image coordinates, then Pi = Ki * [Ri | Ti] must be used.
     where Ki is intrinsic camera matrix for camera i, R is the rotation matrix for camera i, and i is
     the translation vector for camera i.
     following http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
     &lt;/pre&gt;
     * @param camera1 camera matrix for image 1.   the size is 3X4
     *               if x1 and x2 are in camera coordinates, then P1 = [R1 | T1] must be used.
     *       if x1 and x2 are in image coordinates, then P1 = K1 * [R1 | T1] must be used.
     * @param camera2 camera matrix for image 2. the size is 3X4.
     *                 if x1 and x2 are in camera coordinates, then P2 = [R2 | T2] must be used.
     *        if x1 and x2 are in image coordinates, then P2 = K2 * [R2 | T2] must be used.
     * @param x1c the set of measurements of 1 real world point X from camera 1 in camera coordinates or image coords.
     * The corresponding measurements of the same point in camera 2 are in x2.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @param x2c the set of measurements of 1 real world point X from camera 2 in camera coordinates or image coords.
     * The corresponding measurements of the same point in camera 1 are in x1.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @return the 3D coordinate of the point in world scene.  note that
     * the entire array can be normalized by the last element.
     */
    public static WCSPt calculateWCSPoint(
        CameraProjection camera1, CameraProjection camera2,
        double[][] x1c, double[][] x2c) {
        
<span class="nc" id="L184">        return calculateWCSPoint(camera1.getP(), camera2.getP(), x1c, x2c);</span>
    }
    
     /**
     * given the projection matrices and matching correspondence of points between the 2 cameras
      * (measurements of the same object, that is, as a single 3D point is returned) calculate the real world
      * coordinate of the observations.
     *
     &lt;pre&gt;
           if x1 and x2 are in camera coordinates, then Pi = [Ri | Ti] must be used.
           if x1 and x2 are in image coordinates, then Pi = Ki * [Ri | Ti] must be used.
           where Ki is intrinsic camera matrix for camera i, R is the rotation matrix for camera i, and i is
           the translation vector for camera i.
      following http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
      &lt;/pre&gt;
     * @param camera1 camera matrix for image 1.   the size is 3X4
      *               if x1 and x2 are in camera coordinates, then P1 = [R1 | T1] must be used.
      *       if x1 and x2 are in image coordinates, then P1 = K1 * [R1 | T1] must be used.
     * @param camera2 camera matrix for image 2. the size is 3X4.
      *                 if x1 and x2 are in camera coordinates, then P2 = [R2 | T2] must be used.
      *        if x1 and x2 are in image coordinates, then P2 = K2 * [R2 | T2] must be used.
     * @param x1c the set of measurements of 1 real world point X from camera 1 in camera coordinates or image coords.
     * The corresponding measurements of the same point in camera 2 are in x2.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @param x2c the set of measurements of 1 real world point X from camera 2 in camera coordinates or image coords.
     * The corresponding measurements of the same point in camera 1 are in x1.
     * format is 3 x N where N is the number of measurements.
     * If the data are perfect, only need 1 pair of correspondence (i.e. x1[*,0] and x2[*,0]),
     * If the data are not perfect, need more than 1 pair for best fit.
     * @return the 3D coordinate of the point in world scene.  note that
     * the entire array can be normalized by the last element.
     */
    public static WCSPt calculateWCSPoint(double[][] camera1, double[][] camera2,
                                          double[][] x1c, double[][] x2c) {
        
<span class="pc bpc" id="L221" title="2 of 4 branches missed.">        if (camera1.length != 3 || camera1[0].length != 4) {</span>
<span class="nc" id="L222">            throw new IllegalArgumentException(&quot;camera1 must be 3 x 4&quot;);</span>
        }
<span class="pc bpc" id="L224" title="2 of 4 branches missed.">        if (camera2.length != 3 || camera2[0].length != 4) {</span>
<span class="nc" id="L225">            throw new IllegalArgumentException(&quot;camera2 must be 3 x 4&quot;);</span>
        }
<span class="pc bpc" id="L227" title="2 of 4 branches missed.">        if (x1c.length != 3 || x2c.length != 3) {</span>
<span class="nc" id="L228">            throw new IllegalArgumentException(&quot;x1.length must be 3 and so must x2.length&quot;);</span>
        }
<span class="fc" id="L230">        int n = x1c[0].length;</span>
<span class="pc bpc" id="L231" title="1 of 2 branches missed.">        if (x2c[0].length != n) {</span>
<span class="nc" id="L232">            throw new IllegalArgumentException(&quot;x1 and x2 must be same dimensions&quot;);</span>
        }
      
        /*
        following CMU lectures of Kris Kitani:
        http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf
        
        camera matrix P = intrinsic camera matrix times extrinsic camera matrix.
        
        note that the extrinsic matrix has a translation component, and that
        translation is not a linear transformation (see Strang chap 7), so
        the translation is kept separate in most use of it to allow further operations
        to be performed that require rotation and translation to be treated separately.
        
        K = intrinsic camera matrix.
        R = rotation matrix (see euler rotation matrix).
        t = translation vector.
        I = identity matrix.  it's size 3x3 here.
        the '|' is a separation symbol in the matrix to denote that the
            content to the right of it is concatenated to the matrix as column vectors.
        
        Note that the world coordinates can be seen to go through a translation
        then a rotation represented by the extrinsic camera matrix to result in
        homogenous coordinates in the camera reference frame.
            X_c = R * (X_wcs - t)
                = R * X_wcs - R * t
        
             4x1        4x4        4x1
           [ x_c ]                  [ x_wcs ]
           [ y_c ] = [ R  -R*t ] *  [ y_wcs ]
           [ z_c ]   [ 0   1   ]    [ z_wcs ]
           [  1  ]                  [  1    ]
        
        P = K * R * [I | -t]
        
        alternatively, write as P = K * [ R | -R*t]
        
        -----------------------------------
        since data are noisy, these equalities need to be solved as best fit:
        
        x1 = P1 * X1  and  x2 = P2 * X2
            where x1 and x2 are in homogenous coordinates
        
        similarity relation: same direction ray, but have a scale factor alpha
        
        x = alpha * P * X 
            where alpha is a scale factor and so the projection is in the same
               direction.  it's 1./(depth of point)

       NOTE: x_c = K * x_im
             X is in WCS coordinate reference frame.
             x = alpha * P * X
                 if P is [ R | t ], then x is in image coordinates.
                 if P = K * [ R | t ], then x is in camera coordinates
                  (NOTE: sometimes the rotation is first, then P = K * [ R | -R*t])

                    [ p1  p1  p3  p4  ]   [ X ]
        x = alpha * [ p5  p6  p7  p8  ] * [ Y ]
                    [ p9  p10 p11 p12 ]   [ Z ]
                                          [ 1 ]
        
        similarity relations are solved by DLT:
        (Remove scale factor, convert to linear system and solve with SVD)
        
           let pvec_1^T = [ p1 p2 p3 p4 ], pvec_2^T = [ p5 p6 p7 p8 ] etc. 
        
                       1x4               4x1
                    [ --pvec_1^T-- ]   [ X ]
        x = alpha * [ --pvec_2^T-- ] * [ Y ]
                    [ --pvec_3^T-- ]   [ Z ]
                                       [ 1 ]
        
                    [ pvec_1^T * [X,Y,Z,1] ] &lt;-- each row result is 1x1
        x = alpha * [ pvec_2^T * [X,Y,Z,1] ]
                    [ pvec_3^T * [X,Y,Z,1] ]
        
           let Xvec = [ X Y Z 1 ] as a row
        
                    [ pvec_1^T * Xvec ]
        x = alpha * [ pvec_2^T * Xvec ]
                    [ pvec_3^T * Xvec ]
        
        NOTE: The cross product of 2 vectors of the same direction is 0.
        
            So we have 'x cross (P * X) = 0' and alpha drops out

                        [ a2*b3 - a3*b2 ]
                a x b = [ a3*b1 - a1*b3 ]
                        [ a1*b2 - a2*b1 ]

        Can rewrite in terms of cross product:
       
        [ x ]       [ pvec_1^T * Xvec ]   [ y * pvec_3^T * Xvec - pvec_2^T * Xvec    ]   [ 0 ]
        [ y ] cross [ pvec_2^T * Xvec ] = [ pvec_1^T * Xvec - x * pvec_3^T * Xvec    ] = [ 0 ]
        [ 1 ]       [ pvec_3^T * Xvec ]   [ x * pvec_2^T * Xvec - y * pvec_1^T * Xvec]   [ 0 ]
        
        The 3rd line is a linear combination of the first and second lines. (x times the first line plus y times the second line)
        so remove it:

        [ y * pvec_3^T * Xvec - pvec_2^T * Xvec ]   [ 0 ]
        [ pvec_1^T * Xvec - x * pvec_3^T * Xvec ] = [ 0 ]
        
        This is in format A_i * Xvec = 0
        
        can concatenate the 2 rows for the 2nd image in A_i:
        
        [  y1 * p1vec_3^T - p1vec_2^T ]           [ 0 ]
        [ -x1 * p1vec_3^T + p1vec_1^T ] * Xvec  = [ 0 ]
        [  y2 * p2vec_3^T - p2vec_2^T ]           [ 0 ]
        [ -x2 * p2vec_3^T + p2vec_1^T ]           [ 0 ]
        
        solve Xvec in A * Xvec = 0 by minimizing ||A*x||^2 subject to ||x||^2 = 1
        
        Total least squares
        
        Solution is the eigenvector corresponding to smallest eigenvalue of A^T*A.
        */
                
        double u1x, u1y, u2x, u2y;
        double[] tmp;
<span class="fc" id="L352">        double[][] a = new double[4*n][4];</span>
        int i, j;
<span class="fc bfc" id="L354" title="All 2 branches covered.">        for (i = 0, j = 0; i &lt; n; ++i, j+=4) {</span>
<span class="fc" id="L355">            u1x = x1c[0][i];</span>
<span class="fc" id="L356">            u1y = x1c[1][i];</span>
<span class="fc" id="L357">            u2x = x2c[0][i];</span>
<span class="fc" id="L358">            u2y = x2c[1][i];</span>
                        
            //y1 * p1vec[2]^T - p1vec[1]^T
<span class="fc" id="L361">            tmp = Arrays.copyOf(camera1[2], 4);</span>
<span class="fc" id="L362">            MatrixUtil.multiply(tmp, u1y);</span>
<span class="fc" id="L363">            a[j] = MatrixUtil.subtract(tmp, camera1[1]);</span>
            
            //p1vec[0]^T - x1 * p1vec[2]^T
<span class="fc" id="L366">            tmp = Arrays.copyOf(camera1[2], 4);</span>
<span class="fc" id="L367">            MatrixUtil.multiply(tmp, u1x);</span>
<span class="fc" id="L368">            a[j+1] = MatrixUtil.subtract(camera1[0], tmp);</span>
            
            //y2 * p2vec[2]^T - p2vec[1]^T
<span class="fc" id="L371">            tmp = Arrays.copyOf(camera2[2], 4);</span>
<span class="fc" id="L372">            MatrixUtil.multiply(tmp, u2y);</span>
<span class="fc" id="L373">            a[j+2] = MatrixUtil.subtract(tmp, camera2[1]);</span>
            
            //p2vec[0]^T - x2 * p2vec[2]^T
<span class="fc" id="L376">            tmp = Arrays.copyOf(camera2[2], 4);</span>
<span class="fc" id="L377">            MatrixUtil.multiply(tmp, u2x);</span>
<span class="fc" id="L378">            a[j+3] = MatrixUtil.subtract(camera2[0], tmp);</span>
        }
        
        // A is  4*N X 4
        // A^T*A is 4 X 4
<span class="fc" id="L383">        double[][] aTa = MatrixUtil.createATransposedTimesA(a);</span>
<span class="pc bnc" id="L384" title="All 2 branches missed.">        assert(aTa.length == 4);</span>
<span class="pc bnc" id="L385" title="All 2 branches missed.">        assert(aTa[0].length == 4);</span>
        
        //NOTE: SVD(A).V is the same as SVD(A^TA).V
        
<span class="fc" id="L389">        SVD svd = null;</span>
        try {
<span class="fc" id="L391">            svd = SVD.factorize(new DenseMatrix(aTa));</span>
<span class="nc" id="L392">        } catch (NotConvergedException ex) {</span>
<span class="nc" id="L393">            Logger.getLogger(Triangulation.class.getName()).log(Level.SEVERE, null, ex);</span>
<span class="nc" id="L394">            return null;</span>
<span class="fc" id="L395">        }</span>
        
<span class="fc" id="L397">        double[][] vT = MatrixUtil.convertToRowMajor(svd.getVt());</span>
<span class="pc bnc" id="L398" title="All 2 branches missed.">        assert(vT.length == 4);</span>
<span class="pc bnc" id="L399" title="All 2 branches missed.">        assert(vT[0].length == 4);</span>
        
        // eigenvector corresponding to the smallest eigenvalue is last row in svd.V^T
<span class="fc" id="L402">        double[] X = Arrays.copyOf(vT[vT.length - 1], vT[0].length);</span>
<span class="fc" id="L403">        MatrixUtil.multiply(X, 1./X[X.length - 1]);</span>

        /*
        System.out.printf(&quot;x1=\n%s\n&quot;, FormatArray.toString(x1, &quot;%.4e&quot;));
        System.out.printf(&quot;camera1=\n%s\n&quot;, FormatArray.toString(camera1, &quot;%.4e&quot;));
        System.out.printf(&quot;x2=\n%s\n&quot;, FormatArray.toString(x2, &quot;%.4e&quot;));
        System.out.printf(&quot;camera2=\n%s\n&quot;, FormatArray.toString(camera2, &quot;%.4e&quot;));
        System.out.printf(&quot;X=\n%s\n\n&quot;, FormatArray.toString(X, &quot;%.4e&quot;));
        */
        
        // can see that the constraint ||X||^2 = 1 is preserved
                
<span class="fc" id="L415">        double[] x1Rev = MatrixUtil.multiplyMatrixByColumnVector(camera1, X);</span>
<span class="fc" id="L416">        double[] x2Rev = MatrixUtil.multiplyMatrixByColumnVector(camera2, X);        </span>
<span class="fc" id="L417">        double alpha = ((1./x1Rev[2]) + (1./x2Rev[2]))/2.;</span>
        
<span class="fc" id="L419">        MatrixUtil.multiply(x1Rev, 1./x1Rev[2]);</span>
<span class="fc" id="L420">        MatrixUtil.multiply(x2Rev, 1./x2Rev[2]);</span>

        // TODO: consider quality check and correction:  if any points in x1Rev or x2Rev are &lt; 0,
        // TODO: compare x1Rev to x1C, etc
        // TODO: backwards project x1C to XW1 and x2C to XW2 and if they are not the same, take the mean of them

        /*
        System.out.printf(&quot;x1Rev=\n%s\n&quot;, FormatArray.toString(x1Rev, &quot;%.4e&quot;));
        System.out.printf(&quot;x1=\n%s\n&quot;, FormatArray.toString(MatrixUtil.extractColumn(x1, 0), &quot;%.4e&quot;));
        System.out.printf(&quot;x2Rev=\n%s\n&quot;, FormatArray.toString(x2Rev, &quot;%.4e&quot;));        
        System.out.printf(&quot;x2=\n%s\n&quot;, FormatArray.toString(MatrixUtil.extractColumn(x2, 0), &quot;%.4e&quot;));
        */

        //System.out.printf(&quot;alpha=\n%.3e\n&quot;, alpha);
        //MatrixUtil.multiply(X, alpha);

<span class="fc" id="L436">        WCSPt w = new WCSPt();</span>
<span class="fc" id="L437">        w.X = X;</span>
<span class="fc" id="L438">        w.alpha = alpha;</span>

<span class="fc" id="L440">        return w;</span>
    }

    /**
     * for a feature, given image coordinates of the features, camera matrices, and a map from image coordinate index to camera,
     * calculate the location of the point in 3D WCS.
     * @param imageToCameraIndexMap a map from xs index to camera matrix index
     * @param cameras the camera matrices
     * @param x a 3 x n matrix of image coordinates of a point in n images.
     * @return
     */
    public static WCSPt calculateWCSPoint(Map&lt;Integer, Integer&gt; imageToCameraIndexMap,
                                          List&lt;CameraProjection&gt; cameras, double[][] x) {
<span class="pc bpc" id="L453" title="1 of 2 branches missed.">        if (x.length != 3) {</span>
<span class="nc" id="L454">            throw new IllegalArgumentException(&quot;x.length must be 3&quot;);</span>
        }
<span class="fc" id="L456">        int n = x[0].length;</span>
<span class="pc bpc" id="L457" title="1 of 2 branches missed.">        if (n &lt; 2) {</span>
<span class="nc" id="L458">            throw new IllegalArgumentException(&quot;x[0].length must be &gt;= 2&quot;);</span>
        }

        double ux, uy;
        CameraProjection p;
        double[] tmp;
<span class="fc" id="L464">        double[][] a = new double[n * 2][4];</span>
        int i;
<span class="fc bfc" id="L466" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L467">            ux = x[0][i];</span>
<span class="fc" id="L468">            uy = x[1][i];</span>
<span class="fc" id="L469">            p = cameras.get(imageToCameraIndexMap.get(i));</span>

            //y1 * p1vec[2]^T - p1vec[1]^T
<span class="fc" id="L472">            tmp = Arrays.copyOf(p.getP()[2], 4);</span>
<span class="fc" id="L473">            MatrixUtil.multiply(tmp, uy);</span>
<span class="fc" id="L474">            a[2*i] = MatrixUtil.subtract(tmp, p.getP()[1]);</span>

            //p1vec[0]^T - x1 * p1vec[2]^T
<span class="fc" id="L477">            tmp = Arrays.copyOf(p.getP()[2], 4);</span>
<span class="fc" id="L478">            MatrixUtil.multiply(tmp, ux);</span>
<span class="fc" id="L479">            a[2*i+1] = MatrixUtil.subtract(p.getP()[0], tmp);</span>
        }

        // A is  4*N X 4
        // A^T*A is 4 X 4
<span class="fc" id="L484">        double[][] aTa = MatrixUtil.createATransposedTimesA(a);</span>
<span class="pc bnc" id="L485" title="All 2 branches missed.">        assert(aTa.length == 4);</span>
<span class="pc bnc" id="L486" title="All 2 branches missed.">        assert(aTa[0].length == 4);</span>

        //NOTE: SVD(A).V is the same as SVD(A^TA).V

<span class="fc" id="L490">        SVD svd = null;</span>
        try {
<span class="fc" id="L492">            svd = SVD.factorize(new DenseMatrix(aTa));</span>
<span class="nc" id="L493">        } catch (NotConvergedException ex) {</span>
<span class="nc" id="L494">            Logger.getLogger(Triangulation.class.getName()).log(Level.SEVERE, null, ex);</span>
<span class="nc" id="L495">            return null;</span>
<span class="fc" id="L496">        }</span>

<span class="fc" id="L498">        double[][] vT = MatrixUtil.convertToRowMajor(svd.getVt());</span>
<span class="pc bnc" id="L499" title="All 2 branches missed.">        assert(vT.length == 4);</span>
<span class="pc bnc" id="L500" title="All 2 branches missed.">        assert(vT[0].length == 4);</span>

        // eigenvector corresponding to the smallest eigenvalue is last row in svd.V^T
<span class="fc" id="L503">        double[] X = Arrays.copyOf(vT[vT.length - 1], vT[0].length);</span>
<span class="fc" id="L504">        MatrixUtil.multiply(X, 1./X[X.length - 1]);</span>

        // can see that the constraint ||X||^2 = 1 is preserved

<span class="fc" id="L508">        double alpha = 0;</span>
<span class="fc bfc" id="L509" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L510">            p = cameras.get(imageToCameraIndexMap.get(i));</span>
<span class="fc" id="L511">            double[] xRev = MatrixUtil.multiplyMatrixByColumnVector(p.getP(), X);</span>
<span class="fc" id="L512">            alpha += (1./xRev[2]);</span>
        }
<span class="fc" id="L514">        alpha /= n;</span>

        //System.out.printf(&quot;alpha=\n%.3e\n&quot;, alpha);
        //MatrixUtil.multiply(X, alpha);

<span class="fc" id="L519">        WCSPt w = new WCSPt();</span>
<span class="fc" id="L520">        w.X = X;</span>
<span class="fc" id="L521">        w.alpha = alpha;</span>

<span class="fc" id="L523">        return w;</span>
    }

    /*
     * not finished
     * 
     * given a feature in 2 cameras and the rotation and translation between
     * the cameras, estimate the depths and universal scale factor to 
     * return the estimates of the 3-D position.
     &lt;pre&gt;
     The algorithm follows Serge Belongie lectures from Computer Vision II, CSE 252B, USSD
     who refers to Ma, Soatto, Kosecka, and Sastry 2003
     &quot;An Invitation to 3D Vision From Images to Geometric Models&quot; (Chap 5)
     &lt;/pre&gt;
     * @param r rotation of camera 2 with respect to camera 1
     * @param t the translation of camera 2 with respect to camera 1
     * @param x1 coordinates of feature in image 1.   the array should be length
     * @param x2 coordinates of feature in image 1.   the array should be length
     * @return the estimated position of the 3-D point as 2 estimates which should be the same.
     * The depths and universal scale factors are returned also.
     * @throws no.uib.cipr.matrix.NotConvergedException
     */
    /*
    public static WCSResults calculateDepths(double[][] r, double[] t,
        double[] x1, double[] x2) throws NotConvergedException {
        
        // X_2 = R * X_1 + gamma * T where gamma is the universal scale factor
        //
        // lambda_2 * x_2 = lambda_1 * R * x_1 + gamma * T
        //
        // multiply both sides by skew symmetric of x_2 = [x_2]_x to use the property that 
        //     [x_2]_x * x_2 = 0 (i.e. cross product is 0).
        //
        //  [x_2]_x * lambda_2 * x_2 = [x_2]_x * lambda_1 * R * x_1 + [x_2]_x * gamma * T
        //  0 = [x_2]_x * lambda_1 * R * x_1 + [x_2]_x * gamma * T
        //
        // then [ [x_2]_x * R * x_1   [x_2]_x * T ] * [ lambda_1 ] = 0
        //                                            [   gamma  ]
        //          sizes are [ 3X2 ] * [ 2X1 ] = [ 3X1 ]
        //
        // let M = the matrix on right hand side.
        //    this assumes no noise in data
        //  then [lambda_1, gamma] = SVD(M).V^T[last row]
        //  
        //  then X_1 = lambda_1 * x_1
        // 
        //  Then back to the transformation by extrinsic parameters:
        //      lambda_2 * x_2 = lambda_1 * R * x_1 + gamma * T
        //  multiply both sides by skew symmetric of x_1 = [x_1]_x
        //      [x_1]_x * lambda_2 * x_2   =   [x_1]_x * lambda_1 * R * x_1   +   [x_1]_x * gamma * T
        //      [x_1]_x * lambda_2 * x_2   =    0  +   [x_1]_x * gamma * T
        //      [x_1]_x * lambda_2 * x_2  -  [x_1]_x * gamma * T = 0
        //     where gamma is known
        //  
        // then [ [x_1]_x * x_2   -[x_1]_x * gamma * T ] * [ lambda_2 ] = 0
        //                                                 [   1  ]
        //       sizes are [ 3X2 ] * [ 2X1 ] = [ 3X1 ]
        // then [lambda_2, 1] = SVD(M).V^T[last row]
        // X_2 = lambda_2 * x_2
        // 
        // and assert that X_2 = R * X_1 + gamma * T
        
        double[][] x1SkewSym = MatrixUtil.skewSymmetric(x1);
        double[][] x2SkewSym = MatrixUtil.skewSymmetric(x2);
        
        double[] M1Col0 = MatrixUtil.multiplyMatrixByColumnVector(
            MatrixUtil.multiply(x2SkewSym, r), x1
        );
        double[] M1Col1 = MatrixUtil.multiplyMatrixByColumnVector(x2SkewSym, t);
        double[][] M = new double[3][2];
        int i;
        for (i = 0; i &lt; 3; ++i) {
            M[i] = new double[]{M1Col0[i], M1Col1[i]};
        }
        
        MatrixUtil.SVDProducts svd = MatrixUtil.performSVD(M);
        double lambda1 = svd.vT[svd.vT.length - 1][0];
        double gamma = svd.vT[svd.vT.length - 1][1];
        
        double[] X1 = Arrays.copyOf(x2, x2.length);
        MatrixUtil.multiply(X1, lambda1);
        
        // [ [x_1]_x * x_2   -[x_1]_x * gamma * T ]
        M1Col0 = MatrixUtil.multiplyMatrixByColumnVector(x1SkewSym, x2);
        M1Col1 = MatrixUtil.multiplyMatrixByColumnVector(x1SkewSym, t);
        MatrixUtil.multiply(M1Col1, -gamma);
        for (i = 0; i &lt; 3; ++i) {
            M[i] = new double[]{M1Col0[i], M1Col1[i]};
        }
        svd = MatrixUtil.performSVD(M);
        double lambda2 = svd.vT[svd.vT.length - 1][0];
        double one = svd.vT[svd.vT.length - 1][1];
        assert(Math.abs(one) - 1 &lt; 1e-2);
        
        double[] X2 = Arrays.copyOf(x2, x2.length);
        MatrixUtil.multiply(X2, lambda1);
        
        //assert that X_2 = R * X_1 + gamma * T
        double[] gt = Arrays.copyOf(t, t.length);
        MatrixUtil.multiply(gt, gamma);
        double[] checkX2 = MatrixUtil.multiplyMatrixByColumnVector(r, X1);
        checkX2 = MatrixUtil.add(checkX2, gt);
        
        for (i = 0; i &lt; X2.length; ++i) {
            assert(Math.abs(X2[i] - checkX2[i]) &lt; 1.e-2);
        }
        
        WCSResults w = new WCSResults();
        w.setX1(X1);
        w.setX2(X2);
        w.setDepth1(lambda1);
        w.setDepth2(lambda2);
        w.setUniversalScaleFactor(gamma);
        
        return w;
    }
    */
    
    public static class WCSResults {
        /**
         * the 3-D position of point x1 (which should be the same as X2)
         */
        private double[] X1;
        /**
         * the 3-D position of point x2 (which should be the same as X1)
         */
        private double[] X2;
        /**
         * the depth of X1
         */
        private double depth1;
        /**
         * the depth of X2
         */
        private double depth2;
        /**
         * the universal scale factor which is applied to the translation between camera positions
         */
        private double universalScaleFactor;

        /**
         * @return the X1
         */
        public double[] getX1() {
            return X1;
        }

        /**
         * @param X1 the X1 to set
         */
        public void setX1(double[] X1) {
            this.X1 = X1;
        }

        /**
         * @return the X2
         */
        public double[] getX2() {
            return X2;
        }

        /**
         * @param X2 the X2 to set
         */
        public void setX2(double[] X2) {
            this.X2 = X2;
        }

        /**
         * @return the depth1
         */
        public double getDepth1() {
            return depth1;
        }

        /**
         * @param depth1 the depth1 to set
         */
        public void setDepth1(double depth1) {
            this.depth1 = depth1;
        }

        /**
         * @return the depth2
         */
        public double getDepth2() {
            return depth2;
        }

        /**
         * @param depth2 the depth2 to set
         */
        public void setDepth2(double depth2) {
            this.depth2 = depth2;
        }

        /**
         * @return the universalScaleFactor
         */
        public double getUniversalScaleFactor() {
            return universalScaleFactor;
        }

        /**
         * @param universalScaleFactor the universalScaleFactor to set
         */
        public void setUniversalScaleFactor(double universalScaleFactor) {
            this.universalScaleFactor = universalScaleFactor;
        }
        
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>