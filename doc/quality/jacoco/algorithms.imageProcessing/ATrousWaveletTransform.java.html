<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>ATrousWaveletTransform.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Jacoco Report</a> &gt; <a href="index.source.html" class="el_package">algorithms.imageProcessing</a> &gt; <span class="el_source">ATrousWaveletTransform.java</span></div><h1>ATrousWaveletTransform.java</h1><pre class="source lang-java linenums">package algorithms.imageProcessing;

import algorithms.misc.Misc;
import java.util.Arrays;
import java.util.List;

/**
 *
 * @author nichole
 */
<span class="pc bpc" id="L11" title="1 of 2 branches missed.">public class ATrousWaveletTransform {</span>

    /**
    Uses the first step of an A Trous wavelet transform, which is two 1D 
    convolutions of a binomial kernel for sigma=1.
    * @param input
     * @return 
    */
    public GreyscaleImage smoothToSigmaOne(GreyscaleImage input) {
        
<span class="fc" id="L21">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="fc" id="L23">        GreyscaleImage smoothed = scalingFunction.calculate(input);</span>
        
<span class="fc" id="L25">        return smoothed;</span>
    }
    
    /**
    Uses the first step of an A Trous wavelet transform, which is two 1D 
    convolutions of a binomial kernel for sigma=1.
    * @param input
     * @return 
    */
    public Image smoothToSigmaOne(Image input) {
        
<span class="nc" id="L36">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="nc" id="L38">        GreyscaleImage[] smoothed = new GreyscaleImage[3];</span>
<span class="nc" id="L39">        smoothed[0] = input.copyRedToGreyscale();</span>
<span class="nc" id="L40">        smoothed[1] = input.copyGreenToGreyscale();</span>
<span class="nc" id="L41">        smoothed[2] = input.copyRedToGreyscale();</span>
        
<span class="nc bnc" id="L43" title="All 2 branches missed.">        for (int i = 0; i &lt; 3; ++i) {</span>
<span class="nc" id="L44">            smoothed[i] = scalingFunction.calculate(smoothed[i]);</span>
        }
        
<span class="nc" id="L47">        Image out = input.createWithDimensions();</span>
<span class="nc bnc" id="L48" title="All 2 branches missed.">        for (int i = 0; i &lt; input.getNPixels(); ++i) {</span>
<span class="nc" id="L49">            out.setRGB(i, smoothed[0].getValue(i), </span>
<span class="nc" id="L50">                smoothed[1].getValue(i), smoothed[2].getValue(i));</span>
        }
        
<span class="nc" id="L53">        return out;</span>
    }
    
    /**
    Uses the first step of an A Trous wavelet transform, which is two 1D 
    convolutions of a binomial kernel for sigma=0.707 (=sqrt(2)/2).
     * @param input
     * @return 
    */
    public GreyscaleImage smoothToSigmaZeroPointSevenOne(GreyscaleImage input) {
        
<span class="nc" id="L64">        TriangleFunction scalingFunction = new TriangleFunction();</span>
        
<span class="nc" id="L66">        GreyscaleImage smoothed = scalingFunction.calculateNextLevel(input, 0);</span>
        
<span class="nc" id="L68">        return smoothed;</span>
    }

    /**
    Uses the first step of an A Trous wavelet transform, which is two 1D 
    convolutions of a binomial kernel for sigma=0.707 (=sqrt(2)/2).
     * @param input
     * @return 
    */
    public Image smoothToSigmaZeroPointSevenOne(Image input) {
        
<span class="nc" id="L79">        TriangleFunction scalingFunction = new TriangleFunction();</span>
             
<span class="nc" id="L81">        GreyscaleImage[] smoothed = new GreyscaleImage[3];</span>
<span class="nc" id="L82">        smoothed[0] = input.copyRedToGreyscale();</span>
<span class="nc" id="L83">        smoothed[1] = input.copyGreenToGreyscale();</span>
<span class="nc" id="L84">        smoothed[2] = input.copyRedToGreyscale();</span>
        
<span class="nc bnc" id="L86" title="All 2 branches missed.">        for (int i = 0; i &lt; 3; ++i) {</span>
<span class="nc" id="L87">            smoothed[i] = scalingFunction.calculateNextLevel(smoothed[i], 0);</span>
        }
        
<span class="nc" id="L90">        Image out = input.createWithDimensions();</span>
<span class="nc bnc" id="L91" title="All 2 branches missed.">        for (int i = 0; i &lt; input.getNPixels(); ++i) {</span>
<span class="nc" id="L92">            out.setRGB(i, smoothed[0].getValue(i), </span>
<span class="nc" id="L93">                smoothed[1].getValue(i), smoothed[2].getValue(i));</span>
        }
        
<span class="nc" id="L96">        return out;        </span>
    }
    
    /**
     * The a trous algorithm is a fast implementation of a wavelet transform 
     * with no downsampling.   It is non-orthogonal, semi-linear runtime
     * complexity, is invariant under translation, and the transform is 
     * isotropic.
     * Implemented from pseudocode in http://www.multiresolution.com/svbook.pdf
       The scaling function used is the lower resolution choice, the triangle
       * function.
       * &lt;pre&gt;
       * The method uses recursive convolution operations, including previous
       * result to make next.
       * Each convolution uses two passes of one dimensional binomial kernels,
       * starting with the equivalent of sigma=sqrt(2)/2 = 0.707.
       * For each step, the equivalent resulting sigma is from 
       * sigma^2 = sigma_1^2 + sigma_2^2.
       * 
       * outputTransformed[1] = sigma=sqrt(2)/2 convolution
       * outputTransformed[2] = sigma=1 convolution
       * outputTransformed[3] = sqrt( (1)^2 + 1/2) = sqrt(1 + 1/2) convolution
       * outputTransformed[4] = sqrt( 1 + 1/2 + 1/2) = sqrt(2)
       * outputTransformed[5] = sqrt( 2 + 1/2)       = sqrt(2.5)
       * outputTransformed[6] = sqrt( 2 + 1/2 + 1/2) = sqrt(3)
       *  ...
       * &lt;/pre&gt;
     * @param input
     * @param outputTransformed
     * @param outputCoeff 
     */
    public void calculateWithTriangleScalingFunction(GreyscaleImage input,
        List&lt;GreyscaleImage&gt; outputTransformed, List&lt;GreyscaleImage&gt; outputCoeff) {

<span class="nc" id="L130">        int imgDimen = Math.min(input.getWidth(), input.getHeight());</span>

<span class="nc" id="L132">        int nr = (int)(Math.log(imgDimen)/Math.log(2));</span>

<span class="nc" id="L134">        TriangleFunction scalingFunction = new TriangleFunction();</span>
        
<span class="nc" id="L136">        outputTransformed.add(input.copyToSignedImage());</span>
        
<span class="nc" id="L138">        outputCoeff.add(input.createSignedWithDimensions());</span>

<span class="nc bnc" id="L140" title="All 2 branches missed.">        for (int j = 0; j &lt; nr; ++j) {</span>
            
<span class="nc" id="L142">            GreyscaleImage cJ = outputTransformed.get(j);</span>
 
<span class="nc" id="L144">            GreyscaleImage cJPlus1 = scalingFunction.calculateNextLevel(cJ, j);</span>
           
<span class="nc" id="L146">            outputTransformed.add(cJPlus1);</span>
            
            // c_(j,k) − c_(j+1,k)
<span class="nc" id="L149">            GreyscaleImage wJPlus1 = cJ.subtract(cJPlus1);//scalingFunction.subtractLevels(cJ, j);</span>
          
<span class="nc" id="L151">            outputCoeff.add(wJPlus1);</span>
        }
<span class="nc" id="L153">    }</span>

    /**
     * The a trous algorithm is a fast implementation of a wavelet transform 
     * with no downsampling.   It is non-orthogonal, has semi-linear runtime
     * complexity, is invariant under translation, and the transform is 
     * isotropic.
     * Implemented from pseudocode in http://www.multiresolution.com/svbook.pdf
     * The scaling function used is the higher resolution choice, the 3rd order 
     * B Spline function.
     * &lt;pre&gt;
     * The method uses recursive convolution operations, including previous
       * result to make next.
       * Each convolution uses two passes of one dimensional binomial kernels,
       * starting with the equivalent of sigma=1.
       * For each step, the equivalent resulting sigma is from 
       * sigma^2 = sigma_1^2 + sigma_2^2.
       * 
       * outputTransformed[1] = sigma = 1 convolution
       * outputTransformed[2] = sqrt( (1)^2 + (1)^2 ) = sqrt(2) convolution
       * outputTransformed[3] = sqrt( 2 + 1 ) = sqrt(3) convolution
       * outputTransformed[4] = sqrt( 3 + 1 ) = sqrt(4) = 2 convolution
       * outputTransformed[5] = sqrt( 4 + 1 ) = sqrt(5) convolution
       * outputTransformed[6] = sqrt( 5 + 1 ) = sqrt(6) convolution
       * ...
       * outputTransformed[8] = sqrt( 8 + 1 ) = sqrt(9) = 3 convolution
       * &lt;/pre&gt;
     * @param input
     * @param outputTransformed
     * @param outputCoeff 
     */
    public void calculateWithB3SplineScalingFunction(GreyscaleImage input,
        List&lt;GreyscaleImage&gt; outputTransformed, List&lt;GreyscaleImage&gt; outputCoeff) {

<span class="fc" id="L187">        int imgDimen = Math.min(input.getWidth(), input.getHeight());</span>

<span class="fc" id="L189">        int nr = (int)(Math.log(imgDimen)/Math.log(2));</span>

<span class="fc" id="L191">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="fc" id="L193">        outputTransformed.add(input.copyToSignedImage());</span>
        
<span class="fc" id="L195">        outputCoeff.add(input.createSignedWithDimensions());</span>

<span class="fc bfc" id="L197" title="All 2 branches covered.">        for (int j = 0; j &lt; nr; ++j) {</span>
            
<span class="fc" id="L199">            GreyscaleImage cJ = outputTransformed.get(j);</span>
 
<span class="fc" id="L201">            GreyscaleImage cJPlus1 = scalingFunction.calculate(cJ);</span>
           
<span class="fc" id="L203">            outputTransformed.add(cJPlus1);</span>
            
            // c_(j,k) − c_(j+1,k)
<span class="fc" id="L206">            GreyscaleImage wJPlus1 = cJ.subtract(cJPlus1);</span>
            
<span class="fc" id="L208">            outputCoeff.add(wJPlus1);</span>
        }
        
<span class="fc" id="L211">    }</span>
    
    /**
     * The a trous algorithm is a fast implementation of a wavelet transform 
     * with no downsampling.   It is non-orthogonal, has semi-linear runtime
     * complexity, is invariant under translation, and the transform is 
     * isotropic.
     * Implemented from pseudocode in http://www.multiresolution.com/svbook.pdf
     * The scaling function used is the higher resolution choice, the 3rd order 
     * B Spline function.
     * &lt;pre&gt;
     * The method uses recursive convolution operations, including previous
       * result to make next.
       * Each convolution uses two passes of one dimensional binomial kernels,
       * starting with the equivalent of sigma=1.
       * For each step, the equivalent resulting sigma is from 
       * sigma^2 = sigma_1^2 + sigma_2^2.
       * 
       * This method takes an argument stopIter to indicate that only stopIter
       * number of iterations are needed.  For instance, to retrieve only the
       * first populated wavelet, use stopIter = 2 (the first is initialization,
       * and the second is the calculation).
       * &lt;/pre&gt;
     * @param input
     * @param outputTransformed
     * @param outputCoeff
     * @param stopIter
     */
    public void calculateWithB3SplineScalingFunction(GreyscaleImage input,
        List&lt;GreyscaleImage&gt; outputTransformed, List&lt;GreyscaleImage&gt; outputCoeff,
        int stopIter) {

<span class="fc" id="L243">        int imgDimen = Math.min(input.getWidth(), input.getHeight());</span>

<span class="fc" id="L245">        int nr = (int)(Math.log(imgDimen)/Math.log(2));</span>

<span class="pc bpc" id="L247" title="1 of 2 branches missed.">        if (nr &gt; stopIter) {</span>
<span class="fc" id="L248">            nr = stopIter;</span>
        }
        
<span class="fc" id="L251">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="fc" id="L253">        outputTransformed.add(input.copyToSignedImage());</span>
        
<span class="fc" id="L255">        outputCoeff.add(input.createSignedWithDimensions());</span>

<span class="fc bfc" id="L257" title="All 2 branches covered.">        for (int j = 0; j &lt; nr; ++j) {</span>
            
<span class="fc" id="L259">            GreyscaleImage cJ = outputTransformed.get(j);</span>
 
<span class="fc" id="L261">            GreyscaleImage cJPlus1 = scalingFunction.calculate(cJ);</span>
           
<span class="fc" id="L263">            outputTransformed.add(cJPlus1);</span>
            
            // c_(j,k) − c_(j+1,k)
<span class="fc" id="L266">            GreyscaleImage wJPlus1 = cJ.subtract(cJPlus1);</span>
            
<span class="fc" id="L268">            outputCoeff.add(wJPlus1);</span>
        }
        
<span class="fc" id="L271">    }</span>
    
    /**
     * The a trous algorithm is a fast implementation of a wavelet transform 
     * with no downsampling.   It is non-orthogonal, has semi-linear runtime
     * complexity, is invariant under translation, and the transform is 
     * isotropic.
     * Implemented from pseudocode in http://www.multiresolution.com/svbook.pdf
     * The scaling function used is the higher resolution choice, the 3rd order 
     * B Spline function.
     * Edge optimized factors have been included following
     * &quot;Edge-Optimized À-Trous Wavelets for Local Contrast Enhancement with 
     * Robust Denoising&quot; by Johannes Hanika, Holger Dammertz, and Hendrik Lensch
     * https://jo.dreggn.org/home/2011_atrous.pdf
     * 
     *  Not Ready For Use.
     * 
     * NOTE: see PahseCongruence.java instead.  It uses log gabor in frequency
     * space (along with a monogenic filter) and inverse transform to find edges
     * and uses successive scale transformations to help remove noise.
     * The phase congruence produces an edge image, however.
     * 
     * @param input
     * @param outputTransformed
     * @param outputCoeff 
     */
     private void calculateForEdgeOptimization(GreyscaleImage input,
        List&lt;GreyscaleImage&gt; outputTransformed, List&lt;GreyscaleImage&gt; outputCoeff) {

<span class="nc" id="L300">        int imgDimen = Math.min(input.getWidth(), input.getHeight());</span>

<span class="nc" id="L302">        int nr = (int)(Math.log(imgDimen)/Math.log(2));</span>

<span class="nc" id="L304">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="nc" id="L306">        outputTransformed.add(input.copyToSignedImage());</span>
        
<span class="nc" id="L308">        outputCoeff.add(input.createSignedWithDimensions());</span>
                
<span class="nc" id="L310">        int jjMax = 4;</span>
<span class="nc" id="L311">        double lambda = 0.003;</span>
        
<span class="nc" id="L313">        int lastIdx = -1;</span>
<span class="nc" id="L314">        int[] dxs = Misc.dx8;</span>
<span class="nc" id="L315">        int[] dys = Misc.dy8;</span>
        
        // ----- decomposition -----
        
<span class="nc bnc" id="L319" title="All 2 branches missed.">        for (int j = 0; j &lt; nr; ++j) {</span>
            
<span class="nc" id="L321">            GreyscaleImage cJ = outputTransformed.get(j);</span>
 
<span class="nc" id="L323">            GreyscaleImage cJPlus1 = scalingFunction.calculate(cJ);</span>
                        
            // c_(j,k) − c_(j+1,k)
<span class="nc" id="L326">            GreyscaleImage wJPlus1 = cJ.subtract(cJPlus1);</span>
            
//NOTE: the recombined (synthesized) image looks correct, but the
// detail images (in outputCoeff) do not resemble the figure in 
// the authors' paper (unless the authors are plotting the unmodified 
// coefficient image).   
// the negative exponential diminishes the edges
// but a positive exponential, even when sigma is scaled for the range of
// data in wJPlus1 so that it doesn't overflow the range, only enhances the
// pixels that are already bright pixels in the coefficient image, so the
// step seems expensive (exponential transcendantal function) compared to 
// thresholding those same pixels.
//
// the authors' goals may already be met by the use of the A Trous wavelet and
// the b3 spline scaling function already.
            
            // -- alter cJPlus1 and wJPlus1 with edge optimization weights -----
          
<span class="nc" id="L344">            int w = cJ.getWidth();</span>
<span class="nc" id="L345">            int h = cJ.getHeight();</span>
            
<span class="nc" id="L347">            double[][] eI = new double[jjMax*(j + 1)][];</span>
<span class="nc bnc" id="L348" title="All 2 branches missed.">            for (int jj = 0; jj &lt; jjMax*(j + 1); ++jj) {</span>
<span class="nc" id="L349">                double sigmaRJJ = 0.5 + jj;</span>
<span class="nc" id="L350">                double sum0 = 0;</span>
<span class="nc" id="L351">                double sumW = 0;</span>
<span class="nc" id="L352">                double[] ws = new double[wJPlus1.getNPixels()]; </span>
<span class="nc bnc" id="L353" title="All 2 branches missed.">                for (int p = 0; p &lt; wJPlus1.getNPixels(); ++p) {</span>
<span class="nc" id="L354">                    double d = wJPlus1.getValue(p);</span>
<span class="nc" id="L355">                    double m = (d*d)/sigmaRJJ;</span>
                    //range of exp is 0 to 1 if use -m instead
<span class="nc" id="L357">                    double exp = Math.exp(-m);</span>
<span class="nc" id="L358">                    ws[p] = exp;</span>
<span class="nc" id="L359">                    sum0 += cJPlus1.getValue(p);</span>
<span class="nc" id="L360">                    sumW += (exp * cJPlus1.getValue(p));</span>
                }
               
                {
<span class="nc" id="L364">double[] cp = Arrays.copyOf(ws, ws.length);</span>
<span class="nc" id="L365">Arrays.sort(cp);</span>
<span class="nc" id="L366">System.out.println(&quot;j=&quot; + j + &quot; *minW=&quot; + cp[0] + &quot; maxW=&quot; + cp[cp.length - 1]</span>
+ &quot; 1Qw=&quot; +  cp[(int)(1.*(cp.length - 1)/4.)] + &quot; 2Qw=&quot; +  cp[(int)(3.*(cp.length - 1)/4.)]
+ &quot; 3QW=&quot; + cp[(int)(3.*(cp.length - 1)/4.)]);
                } 
                
                // normalize ws
<span class="nc" id="L372">                double f0 = (sum0/sumW);</span>
<span class="nc bnc" id="L373" title="All 2 branches missed.">                for (int p = 0; p &lt; cJ.getNPixels(); ++p) {</span>
<span class="nc" id="L374">                    ws[p] *= f0;</span>
                }
                
<span class="nc" id="L377">                eI[jj] = new double[cJ.getNPixels()];</span>
 
                {
<span class="nc" id="L380">double[] cp = Arrays.copyOf(ws, ws.length);</span>
<span class="nc" id="L381">Arrays.sort(cp);</span>
<span class="nc" id="L382">System.out.println(&quot;j=&quot; + j + &quot; minW=&quot; + cp[0] + &quot; maxW=&quot; + cp[cp.length - 1]</span>
+ &quot; 1Qw=&quot; +  cp[(int)(1.*(cp.length - 1)/4.)] + &quot; 2Qw=&quot; +  cp[(int)(3.*(cp.length - 1)/4.)]
+ &quot; 3QW=&quot; + cp[(int)(3.*(cp.length - 1)/4.)]);
                }
 
<span class="nc bnc" id="L387" title="All 2 branches missed.">                for (int p = 0; p &lt; cJ.getNPixels(); ++p) {</span>
                                        
<span class="nc" id="L389">                    double dIJJ = cJ.getValue(p) - (ws[p] * cJPlus1.getValue(p));</span>
                    
<span class="nc" id="L391">                    ++lastIdx;</span>
<span class="nc bnc" id="L392" title="All 2 branches missed.">                    if (lastIdx &gt; (dxs.length - 1)) {</span>
<span class="nc" id="L393">                        lastIdx = 0;</span>
                    }

                    // NOTE: assuming authors intend gC to describe the unmodified cJ
<span class="nc" id="L397">                    double gC = estimateLocalNoise(cJ, p, dxs[lastIdx], dys[lastIdx]);</span>
                    
<span class="nc" id="L399">                    eI[jj][p] = (dIJJ * dIJJ) + (lambda * gC);</span>
                }
            }
<span class="nc" id="L402">            double[] sigmas = new double[cJ.getNPixels()];</span>
            
            // for each pixel p, find the minimum in eI and store it's sigma.
            // then use a B3Spline on the sigma image to result in the sigmas
            // to be used per pixel on cJ and then calculate the detail image again
<span class="nc bnc" id="L407" title="All 2 branches missed.">            for (int p = 0; p &lt; cJ.getNPixels(); ++p) {</span>
<span class="nc" id="L408">                double minE = Double.MAX_VALUE;</span>
<span class="nc" id="L409">                int minEJJIdx = -1;</span>
<span class="nc bnc" id="L410" title="All 2 branches missed.">                for (int jj = 0; jj &lt; jjMax*(j + 1); ++jj) {</span>
<span class="nc" id="L411">                    double e = eI[jj][p];</span>
<span class="nc bnc" id="L412" title="All 2 branches missed.">                    if (e &lt; minE) {</span>
<span class="nc" id="L413">                        minE = e;</span>
<span class="nc" id="L414">                        minEJJIdx = jj;</span>
                    }
                }
<span class="nc" id="L417">                sigmas[p] =  0.5 + minEJJIdx;</span>
            }
<span class="nc" id="L419">            sigmas = scalingFunction.calculate(sigmas, w, h);</span>
            
            // use the sigmas and weighting function to alter cJPlus1 and recalc wJPlus1
<span class="nc" id="L422">            double sumW = 0;</span>
<span class="nc" id="L423">            double sum0 = 0;</span>
<span class="nc" id="L424">            double[] ws = new double[wJPlus1.getNPixels()];</span>
<span class="nc bnc" id="L425" title="All 2 branches missed.">            for (int p = 0; p &lt; wJPlus1.getNPixels(); ++p) {</span>
<span class="nc" id="L426">                double sigma = sigmas[p];</span>
<span class="nc bnc" id="L427" title="All 4 branches missed.">                assert(sigma &gt; 0.0);</span>
<span class="nc" id="L428">                double d = wJPlus1.getValue(p);</span>
<span class="nc" id="L429">                double m = (d*d)/sigma;</span>
<span class="nc" id="L430">                double exp = Math.exp(-m);</span>
<span class="nc" id="L431">                ws[p] = exp;</span>
<span class="nc" id="L432">                sum0 += cJPlus1.getValue(p);</span>
<span class="nc" id="L433">                sumW += (exp * cJPlus1.getValue(p));</span>
            }
<span class="nc" id="L435">            double f0 = (sum0/sumW);</span>
<span class="nc bnc" id="L436" title="All 2 branches missed.">            for (int p = 0; p &lt; cJ.getNPixels(); ++p) {</span>
<span class="nc" id="L437">                double f = ws[p] * f0;</span>
<span class="nc" id="L438">                int cIJJPlus1 = (int)Math.round(f * cJPlus1.getValue(p));</span>
<span class="nc bnc" id="L439" title="All 2 branches missed.">                if (cIJJPlus1 &gt; 255) {</span>
<span class="nc" id="L440">                    System.err.println(&quot;larger than 255.  factor=&quot; + f);</span>
<span class="nc" id="L441">                    cIJJPlus1 = 255;</span>
                }
                
<span class="nc" id="L444">                cJPlus1.setValue(p, cIJJPlus1);</span>
            }
            
<span class="nc" id="L447">            wJPlus1 = cJ.subtract(cJPlus1);</span>
                             
<span class="nc" id="L449">            outputTransformed.add(cJPlus1);</span>
                        
<span class="nc" id="L451">            outputCoeff.add(wJPlus1);</span>
            
            /*
            estimate sigma per pixel:
                compute multiple decompositions with different parameters and 
                then choose optimal parameters for each pixel. 
            The parameters to iterate over are sigma_r_j for jj=0 to jjmax.

            For each jj we separate the current image into coarse c_j_jj and
            detail using the current σ_r_jj as global edge weight. 
            The resulting decomposition is used to evaluate an error image
              e_jj = d_j_jj squared  + λ · || ∇c_j_jj ||
            
            The authors use a fixed  λ = 0.003 and jmax=4.
            The error measure is evaluated using same window as used in b3 spline
            function, using 25 samples on a regular grid with 
            Cranley Patterson rotation [CP76] 
            to decorrelate adjacent pixels.
            
            After all jj have been processed at scale j, we search for the
            minimum error e_jj per pixel 
            and determine the optimal edge weight σ_r_k with k = argmin_jj{e_jj}. 
            In order to avoid too drastic changes in the edge weights, 
            the per-pixel weights are smoothed once into a buffer z
               z = σ_r_k ∗ h_0   (h_0 represents the b3 spline window function)
            
            Finally, the actual wavelet decomposition step takes place
            as in Section 2.1, but taking the locally optimal parameters
            σ_r from the blended buffer z at each pixel’s position.
            We found jmax = 4 sufficient for all images in this paper,
            and chose a simple linear sampling of the interval
            [0,4∗(j+1)). 
           
            Synthesis is recombining the coarse base layer with the coefficient
            (detail) layers that are potentially scaled and soft thresholded.
            
            BayesShrink [CYV00] is a soft thresholding method designed for a 
            wide range of input signal priors, such as Laplacian and 
            Gaussian distributions assuming additive iid Gaussian noise.
            As a consistent and robust estimator for the noise standard
            deviation, we use the median absolute deviation (MAD) over
            all pixels at the finest level, and obtain
                σ_n = median(|d0|) / 0.6745
            Now we iterate for each wavelet scale, this time starting at
            the coarsest level i = imax...0. Given the signal variance (σ_y_i)^2
            the soft shrinkage threshold T is calculated as in [CYV00]
            to minimize the risk of destroying the signal, by
                T = ( (σ_n_i)^2 ) / sqrt( max{0, (σ_y_i)^2 - (σ_n_i)^2} )

                with 
                   (σ_y_i)^2 = (1/N) * summation over pixels of (d_i)^2 
                and
                    (σ_n_i)^2 = σ_n,i = σ_n / (2^i)
            
                With this threshold, shrinkage and contrast boost is applied
                to the detail coefficients at the same time, by setting
                    modified d_i = max{0,|di| −T} ·sign(di)
                      and ci−1 = ci +β · modified d_i
                where β is the contrast boost parameter. In case denoising is
                not wanted, only the last step is relevant with modified d = d.

            Our edge-optimized wavelet scheme tends to move as
            much edge information to the coarser levels as possible, so
            the detail coefficients even correspond more to the Gaussian
            distribution than they would with usual wavelet transformation.
            Also, the edge data will not be affected by thresholding
            this way, resulting in a better PSNR of the denoised results.
            */
           
        }
        
<span class="nc" id="L522">    }</span>
   
    /**
     * same as calculateWithB3SplineScalingFunction except that it uses a 2-D
     * scaling function and the runtime is 2.5 times longer.
     * 
     * @param input
     * @param outputTransformed
     * @param outputCoeff 
     */
    void calculateWithB3SplineScalingFunction2(GreyscaleImage input,
        List&lt;GreyscaleImage&gt; outputTransformed, List&lt;GreyscaleImage&gt; outputCoeff) {

<span class="fc" id="L535">        int imgDimen = Math.min(input.getWidth(), input.getHeight());</span>

<span class="fc" id="L537">        int nr = (int)(Math.log(imgDimen)/Math.log(2));</span>

<span class="fc" id="L539">        B3SplineFunction scalingFunction = new B3SplineFunction();</span>
        
<span class="fc" id="L541">        outputTransformed.add(input.copyToSignedImage());</span>
        
<span class="fc" id="L543">        outputCoeff.add(input.createSignedWithDimensions());</span>

<span class="fc bfc" id="L545" title="All 2 branches covered.">        for (int j = 0; j &lt; nr; ++j) {</span>
            
<span class="fc" id="L547">            GreyscaleImage cJ = outputTransformed.get(j);</span>
 
<span class="fc" id="L549">            GreyscaleImage cJPlus1 = scalingFunction.calculate2D(cJ);</span>
           
<span class="fc" id="L551">            outputTransformed.add(cJPlus1);</span>
            
            // c_(j,k) − c_(j+1,k)
<span class="fc" id="L554">            GreyscaleImage wJPlus1 = cJ.subtract(cJPlus1);</span>
            
<span class="fc" id="L556">            outputCoeff.add(wJPlus1);</span>
        }
        
<span class="fc" id="L559">    }</span>

    public GreyscaleImage reconstruct(GreyscaleImage c0, 
        List&lt;GreyscaleImage&gt; mmCoeff) {

<span class="fc" id="L564">        int nr = mmCoeff.size();</span>

<span class="fc" id="L566">        GreyscaleImage output = c0.copyToFullRangeIntImage();</span>

<span class="fc bfc" id="L568" title="All 2 branches covered.">        for (int j = 0; j &lt; nr; ++j) {</span>
           
<span class="fc" id="L570">            output = output.add(mmCoeff.get(j));</span>
        }

<span class="fc" id="L573">        return output;</span>
    }
    
    /*
    looking at
    A Novel Edge-Aware A-Trous Filter For Single Image Dehazing `
        Baojun Qi, Tao Wu, and Hangen He
    2012 IEEE International Conference on Information Science and Technology
        Wuhan, Hubei, China; March 23-25, 2012
    
    the input transformed images are found above as c_(j,k), c_(j+1,k), etc
                                    (   | (c(j, k) - c(j + 1, k) | )
        edge stopping function = exp( - -------------------------- )
                                    (         (sigma_r)^2          )
    
        so this is using what the above refers to as the coefficients (retained
        for use in reconstruction).
    
    the transformed image is multiplied by the edge stopping function divided
        by the normalization.
    
    the normalization is needed too.
    
    looking for edge optimization which avoids exponentiation if possible.
    https://jo.dreggn.org/home/2011_atrous.pdf
    similar transform as implemented in above class plus
    locally adaptive (per-pixel) edge-weights, improved
    denoising using BayesShrink, and a fast and simple to implement
    algorithm
    
    see pg 37 of sv book
    */

    /**
     * Following
     * &quot;Edge-Optimized À-Trous Wavelets for Local Contrast Enhancement with 
     * Robust Denoising&quot; by Johannes Hanika, Holger Dammertz, and Hendrik Lensch
     * https://jo.dreggn.org/home/2011_atrous.pdf
     * to estimate del c_i_jj as part of creating an error image.
     * The authors calculate gradient c_i_jj using Cranley Patterson rotation 
       sampling within the A Trous B3Spline window (which is 25 pixels).
       
       This looks a little like calculating auto-correlation, except not wanting 
       the center pixel as the fixed first pixel of the difference.
       
       If gradient c_i_jj is meant to be a measure of local image noise, would 
       presumably want to select only differences between adjacent pixel pairs.
       So the use of Cranley Patterson rotation must be in selecting the second
       point using an offset chosen from the vector U of values.
       That offset is applied uniformly to the set to help choose the 2nd point.
       The universe of offsets U can only be the offsets to result in the 8
       neighbor region.
        
       Not sure, but I think that is what the authors implemented.
        
       Given to this method are the center pixel index for the A Trous window
       and the offsets as dx and dy chosen from the universe U of 8 neigbhor
       offsets.
        
       For each pixel in the window, will determine its intensity difference 
       from the pixel and the pixel that is it's coordinates plus the offsets.
       The result returned will be the average of those.
       
       Note that another paper 
       (&quot;Efficient Multidimensional Sampling&quot; by Kollig and Keller, 
       http://www.uni-kl.de/AG-Heinrich/EMS.pdf)
       suggests different sampling methods, so may change this in the future.
        
     * @return 
     */
    private double estimateLocalNoise(GreyscaleImage img, int pixIdx, int xOffset, 
        int yOffset) {
        
<span class="nc" id="L646">        int w = img.getWidth();</span>
<span class="nc" id="L647">        int h = img.getHeight();</span>
        
<span class="nc" id="L649">        int x = img.getCol(pixIdx);</span>
<span class="nc" id="L650">        int y = img.getRow(pixIdx);</span>
        
<span class="nc" id="L652">        int count = 0;</span>
<span class="nc" id="L653">        double diff = 0;</span>
        // iterate within window to find first pixel
<span class="nc bnc" id="L655" title="All 2 branches missed.">        for (int dx = -2; dx &lt;= 2; ++dx) {</span>
<span class="nc" id="L656">            int x1 = x + dx;</span>
<span class="nc bnc" id="L657" title="All 4 branches missed.">            if (x1 &lt; 0 || x1 &gt; (w - 1)) {</span>
<span class="nc" id="L658">                continue;</span>
            }
<span class="nc bnc" id="L660" title="All 2 branches missed.">            for (int dy = -2; dy &lt;= 2; ++dy) {</span>
<span class="nc" id="L661">                int y1 = y + dy;</span>
<span class="nc bnc" id="L662" title="All 4 branches missed.">                if (y1 &lt; 0 || y1 &gt; (h - 1)) {</span>
<span class="nc" id="L663">                    continue;</span>
                }
                                
<span class="nc" id="L666">                int x2 = x1 + xOffset;</span>
<span class="nc" id="L667">                int y2 = y1 + yOffset;</span>
<span class="nc bnc" id="L668" title="All 8 branches missed.">                if ((x2 &lt; 0) || (x2 &gt; (w - 1)) || (y2 &lt; 0) ||</span>
                    (y2 &gt; (h - 1))) {
<span class="nc" id="L670">                    continue;</span>
                }
                                
<span class="nc" id="L673">                diff += Math.abs(img.getValue(x1, y1) - img.getValue(x2, y2));</span>
                
<span class="nc" id="L675">                count++;</span>
            }
        }
<span class="nc bnc" id="L678" title="All 4 branches missed.">        assert(count &gt; 0);</span>
        
<span class="nc" id="L680">        diff /= (double)count;</span>
        
<span class="nc" id="L682">        return diff;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.5.201505241946</span></div></body></html>