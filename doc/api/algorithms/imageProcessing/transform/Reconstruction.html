<!DOCTYPE HTML>
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (11.0.14.1) on Wed Nov 09 18:45:58 PST 2022 -->
<title>Reconstruction</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2022-11-09">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../jquery/jquery-ui.css" title="Style">
<script type="text/javascript" src="../../../script.js"></script>
<script type="text/javascript" src="../../../jquery/jszip/dist/jszip.min.js"></script>
<script type="text/javascript" src="../../../jquery/jszip-utils/dist/jszip-utils.min.js"></script>
<!--[if IE]>
<script type="text/javascript" src="../../../jquery/jszip-utils/dist/jszip-utils-ie.min.js"></script>
<![endif]-->
<script type="text/javascript" src="../../../jquery/jquery-3.5.1.js"></script>
<script type="text/javascript" src="../../../jquery/jquery-ui.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="Reconstruction";
        }
    }
    catch(err) {
    }
//-->
var data = {"i0":9,"i1":9,"i2":9,"i3":9,"i4":9,"i5":9,"i6":9,"i7":9,"i8":9,"i9":9,"i10":9};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
var pathtoroot = "../../../";
var useModuleDirectories = true;
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<header role="banner">
<nav role="navigation">
<div class="fixedNav">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a id="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a id="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses.html">All&nbsp;Classes</a></li>
</ul>
<ul class="navListSearch">
<li><label for="search">SEARCH:</label>
<input type="text" id="search" value="search" disabled="disabled">
<input type="reset" id="reset" value="reset" disabled="disabled">
</li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a id="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
</div>
<div class="navPadding">&nbsp;</div>
<script type="text/javascript"><!--
$('.navPadding').css('padding-top', $('.fixedNav').css("height"));
//-->
</script>
</nav>
</header>
<!-- ======== START OF CLASS DATA ======== -->
<main role="main">
<div class="header">
<div class="subTitle"><span class="packageLabelInType">Package</span>&nbsp;<a href="package-summary.html">algorithms.imageProcessing.transform</a></div>
<h2 title="Class Reconstruction" class="title">Class Reconstruction</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>algorithms.imageProcessing.transform.Reconstruction</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<pre>public class <span class="typeNameLabel">Reconstruction</span>
extends java.lang.Object</pre>
<div class="block">This class has/will have methods for Structure from Motion and 3-D point reconstruction.
 given correspondence between two images calculate the camera
 parameters as intrinsic and extrinsic parameters,
 and the real world position.

 TODO: implement affine reconstruction for the case of pure translation,
     see Example 6.6 of Ma, Soatto, Kosecká, and Sastry 2012, "An Invitation to 3-D Vision"".
     For the case of pure rotation, see Example 6.10.

 Euler rotations:
        
        about z-axis (yaw):           about x-axis (roll):       about the y-axis (pitch):
            | cos φ   -sin φ    0 |    |    1       0       0 |  |  cos ψ    0  sin ψ |
            | sin φ    cos φ    0 |    |    0   cos θ   sin θ |  |      0    1      0 |
            |     0        0    1 |    |    0  -sin θ   cos θ |  | -sin ψ    0  cos ψ |        
        
 useful reading:
  http://www.cs.cmu.edu/~16385/s17/Slides/12.5_Reconstruction.pdf
  Fig 1.8 of "Computing Intrinsic Images" by Aloimonos 1986 for a snapshot in time of c.v. algorithms

   Motion - the rotation and translation of an object in front of a camera.
            sometimes represented as the 3X4 projection matria P = |R | t|
   Shape - the local surface orientation where surface orientation is 
           usually the surface normal vector.
           sometimes represented by X, the 3-D coordinates w.r.t. a world reference system.
           From "Computing Intrinsic Images" by Aloimonos 1986
             perspective projection is pinhole camera.
             Under orthographic projection, the image coordinates of a point 
             are equal to the corresponding 3-D coordinates, i.e. (x.y ) =(X,Y)
             and we do not know its depth.
   Depth - the Z-coordinate of a 3-D object in the world coordinate system.

   test datasets:
      https://www.cs.cmu.edu/afs/cs/project/vision/vasc/idb/www/html_permanent/index.html
      http://www.cs.cmu.edu/afs/cs/project/cil/www/v-images.html
       
      
 TODO: implement more of Chap 11 of MASKS (Ma, Soatto, Kosecká, and Sastry 2012, 
 "An Invitation to 3-D Vision")
 
 </pre></div>
<dl>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>nichole</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<section role="region">
<ul class="blockList">
<li class="blockList"><a id="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colSecond" scope="col">Class</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="Reconstruction.MotionAndStructure.html" title="class in algorithms.imageProcessing.transform">Reconstruction.MotionAndStructure</a></span></code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="Reconstruction.OrthographicProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.OrthographicProjectionResults</a></span></code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="Reconstruction.ParaperspectiveProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ParaperspectiveProjectionResults</a></span></code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="Reconstruction.ProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ProjectionResults</a></span></code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="Reconstruction.ReconstructionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ReconstructionResults</a></span></code></th>
<td class="colLast">&nbsp;</td>
</tr>
</table>
</li>
</ul>
</section>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<section role="region">
<ul class="blockList">
<li class="blockList"><a id="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Constructor</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tr class="altColor">
<th class="colConstructorName" scope="row"><code><span class="memberNameLink"><a href="#%3Cinit%3E()">Reconstruction</a></span>()</code></th>
<td class="colLast">&nbsp;</td>
</tr>
</table>
</li>
</ul>
</section>
<!-- ========== METHOD SUMMARY =========== -->
<section role="region">
<ul class="blockList">
<li class="blockList"><a id="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colSecond" scope="col">Method</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>(package private) static <a href="Reconstruction.OrthographicProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.OrthographicProjectionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#_DoNotUseThisCalculateAffineReconstruction(double%5B%5D%5B%5D,int)">_DoNotUseThisCalculateAffineReconstruction</a></span>&#8203;(double[][]&nbsp;x,
                                          int&nbsp;mImages)</code></th>
<td class="colLast">
<div class="block">NOT READY FOR USE.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static <a href="Reconstruction.OrthographicProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.OrthographicProjectionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateAffineReconstruction(double%5B%5D%5B%5D,int)">calculateAffineReconstruction</a></span>&#8203;(double[][]&nbsp;x,
                             int&nbsp;mImages)</code></th>
<td class="colLast">
<div class="block">NOTE: not ready for use yet.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static <a href="Reconstruction.ParaperspectiveProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ParaperspectiveProjectionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateParaperspectiveReconstruction(double%5B%5D%5B%5D,int)">calculateParaperspectiveReconstruction</a></span>&#8203;(double[][]&nbsp;x,
                                      int&nbsp;mImages)</code></th>
<td class="colLast">
<div class="block">NOT READY FOR USE.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>static double[][]</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateProjectiveHomographyWithLeastSquares(double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D)">calculateProjectiveHomographyWithLeastSquares</a></span>&#8203;(double[][]&nbsp;x1P,
                                             double[][]&nbsp;x2P,
                                             double[][]&nbsp;fm,
                                             double[]&nbsp;e2)</code></th>
<td class="colLast">
<div class="block">NOT READY FOR USE YET.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static <a href="Camera.CameraExtrinsicParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraExtrinsicParameters</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateProjectiveMotion(double%5B%5D%5B%5D,double%5B%5D%5B%5D)">calculateProjectiveMotion</a></span>&#8203;(double[][]&nbsp;x1,
                         double[][]&nbsp;x2)</code></th>
<td class="colLast">
<div class="block">estimate the extrinsic camera matrix P2 assuming P1 is[I|0]
 using epipolar geometry.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static <a href="Reconstruction.ProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ProjectionResults</a>[]</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateProjectiveReconstruction(double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D)">calculateProjectiveReconstruction</a></span>&#8203;(double[][]&nbsp;intr1,
                                 double[][]&nbsp;intr2,
                                 double[][]&nbsp;x1,
                                 double[][]&nbsp;x2)</code></th>
<td class="colLast">
<div class="block">estimate the projection matrices P1 and P2 and triangulate the points x1 and x2 to derive the location of the WCS object
 using planar homography.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>static <a href="Reconstruction.ProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ProjectionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateProjectiveReconstruction(double%5B%5D%5B%5D,int)">calculateProjectiveReconstruction</a></span>&#8203;(double[][]&nbsp;x,
                                 int&nbsp;mImages)</code></th>
<td class="colLast">
<div class="block">NOT READY FOR USE
 TODO: proof read the algorithm and write test for this.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static <a href="Reconstruction.ReconstructionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ReconstructionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateReconstruction(algorithms.imageProcessing.transform.Camera.CameraParameters,algorithms.imageProcessing.transform.Camera.CameraParameters,double%5B%5D%5B%5D,double%5B%5D%5B%5D)">calculateReconstruction</a></span>&#8203;(<a href="Camera.CameraParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraParameters</a>&nbsp;camera1,
                       <a href="Camera.CameraParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraParameters</a>&nbsp;camera2,
                       double[][]&nbsp;x1c,
                       double[][]&nbsp;x2c)</code></th>
<td class="colLast">
<div class="block">given 2 sets of correspondence from 2 different images taken from
 2 cameras whose intrinsic and extrinsic parameters are known,
 determine the world scene coordinates of the correspondence points.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static <a href="Reconstruction.ReconstructionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ReconstructionResults</a></code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#calculateUsingEssentialMatrix(double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D)">calculateUsingEssentialMatrix</a></span>&#8203;(double[][]&nbsp;intr1,
                             double[][]&nbsp;intr2,
                             double[][]&nbsp;x1,
                             double[][]&nbsp;x2)</code></th>
<td class="colLast">
<div class="block">NOTE: the method needs improvement to choose the best 2 solutions, meanwhile prefer to use
 calculateProjectiveReconstruction(double[][] x1c, double[][] x2c).</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>(package private) static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#populateWithDet1Rs(double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D%5B%5D)">populateWithDet1Rs</a></span>&#8203;(double[][]&nbsp;u,
                  double[][]&nbsp;vT,
                  double[][]&nbsp;r1Out,
                  double[][]&nbsp;r2Out,
                  double[][]&nbsp;uOut)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static <a href="Reconstruction.MotionAndStructure.html" title="class in algorithms.imageProcessing.transform">Reconstruction.MotionAndStructure</a>[]</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#solveFor4Projective(double%5B%5D%5B%5D,double%5B%5D%5B%5D,double%5B%5D)">solveFor4Projective</a></span>&#8203;(double[][]&nbsp;x1,
                   double[][]&nbsp;x2,
                   double[]&nbsp;outV3)</code></th>
<td class="colLast">
<div class="block">estimate the projection matrices P1 and P2 using planar homography.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a id="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</section>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<section role="region">
<ul class="blockList">
<li class="blockList"><a id="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a id="&lt;init&gt;()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>Reconstruction</h4>
<pre>public&nbsp;Reconstruction()</pre>
</li>
</ul>
</li>
</ul>
</section>
<!-- ============ METHOD DETAIL ========== -->
<section role="region">
<ul class="blockList">
<li class="blockList"><a id="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a id="calculateReconstruction(algorithms.imageProcessing.transform.Camera.CameraParameters,algorithms.imageProcessing.transform.Camera.CameraParameters,double[][],double[][])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateReconstruction</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.ReconstructionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ReconstructionResults</a>&nbsp;calculateReconstruction&#8203;(<a href="Camera.CameraParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraParameters</a>&nbsp;camera1,
                                                                           <a href="Camera.CameraParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraParameters</a>&nbsp;camera2,
                                                                           double[][]&nbsp;x1c,
                                                                           double[][]&nbsp;x2c)
                                                                    throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">given 2 sets of correspondence from 2 different images taken from
 2 cameras whose intrinsic and extrinsic parameters are known,
 determine the world scene coordinates of the correspondence points.
 This method simply uses triangulation on each correspondence pair.
 <pre>
 following CMU lectures of Kris Kitani at 
 http://www.cs.cmu.edu/~16385/s17/Slides/12.5_Reconstruction.pdf
 
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>camera1</code> - image 1 camera matrices of intrinsic and extrinsic parameters.
 the size is 3 x 4.</dd>
<dd><code>camera2</code> - image 2 camera matrices of intrinsic and extrinsic parameters.
 the size is 3 x 4.</dd>
<dd><code>x1c</code> - the image 1 set of correspondence points in camera coordinates.  format is 3 x N where
 N is the number of points.</dd>
<dd><code>x2c</code> - the image 2 set of correspondence points in camera coordinates.  format is 3 x N where
 N is the number of points.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the world scene coordinates and the intrinsic and extrinsic
 camera matrices (the later were given to the code, but are convenient to return in results).</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateProjectiveMotion(double[][],double[][])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateProjectiveMotion</h4>
<pre class="methodSignature">public static&nbsp;<a href="Camera.CameraExtrinsicParameters.html" title="class in algorithms.imageProcessing.transform">Camera.CameraExtrinsicParameters</a>&nbsp;calculateProjectiveMotion&#8203;(double[][]&nbsp;x1,
                                                                         double[][]&nbsp;x2)
                                                                  throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">estimate the extrinsic camera matrix P2 assuming P1 is[I|0]
 using epipolar geometry.
 The essential matrix contains information about the relative position
 T and orientation R between 2 cameras (the camera pose).
 The best of 4 solutions constructed from the essential matrix is returned
 where the best is defined using the volume of each point's epipolar plane
 with respect to the signs of the scales (scale in x = scale * P * X).

 The projective calibration can be upgraded to
     affine (parallelism preserved) and Euclidean (parallelism and orthogonality preserved) 
     reconstructions.
     To upgrade to an affine projection, need 3 vanishing points
     (see Section 9.2.2 of Belongie lec 9).
     To directly upgrade from projective to euclidean projection, need
     5 ground truth points in general position, that is, no 4 points
     are coplanar (see Section 9.3 of Belongie lec 9).
 NOTE: this solution is fine for cases with no noise, otherwise, the
 results should be the initial values for a non-linear optimization method.

 <pre>
 MASKS chap. 5 and their code essentialDiscrete.m
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x1</code> - the camera 1 set of image correspondence points in the reference frame of the camera.
 format is 3 x N where N is the number of points.
 NOTE: one can guess at the camera intrinsic matrix if needed, in order to calibrate the camera.
 MASKS gives advice in Algorithm 11.6 step 1.</dd>
<dd><code>x2</code> - the camera 2 set of image correspondence points in the reference frame of the camera.
 format is 3 x N where N is the number of points.
 NOTE: one can guess at the camera intrinsic matrix if needed, in order to calibrate the camera.
 MASKS gives advice in Algorithm 11.6 step 1.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the estimated projections P1 and P2 and the objects locations as 3-D points.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateProjectiveReconstruction(double[][],double[][],double[][],double[][])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateProjectiveReconstruction</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.ProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ProjectionResults</a>[]&nbsp;calculateProjectiveReconstruction&#8203;(double[][]&nbsp;intr1,
                                                                                   double[][]&nbsp;intr2,
                                                                                   double[][]&nbsp;x1,
                                                                                   double[][]&nbsp;x2)
                                                                            throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">estimate the projection matrices P1 and P2 and triangulate the points x1 and x2 to derive the location of the WCS object
 using planar homography.
 This is also called Projective Structure From Motion for the
 Two-camera case.   it's a distorted version of euclidean 3d.

 NOTE that because the camera calibration, that is, intrinsic parameters,
 are not known, only the projective reconstruction is possible,
 but this can be upgraded to
     affine (parallelism preserved) and Euclidean (parallelism and orthogonality preserved)
     reconstructions.
     To upgrade to an affine projection, need 3 vanishing points
     (see Example 6.5 of MASKS).
     To directly upgrade from projective to euclidean projection, need
     5 ground truth points in general position, that is, no 4 points
     are coplanar (see Section 9.3 of Belongie lec 9. and MASKS chap 5 "Historical Notes" and Algorithm 11.7).

 <pre>
 following "An Invitation to 3-D Vision" by Ma,  Soatto,  Kosecká, and Sastry
 noted as MASKS.
 Algorithm 5.2 in Chapter 5 and their code homography2Motion.m from
 https://cs.gmu.edu/~kosecka/bookcode.html
 which is free for non-commercial use.
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x1</code> - the image 1 set of correspondence points.  format is 3 x N where
 N is the number of points.
 NOTE: since intrinsic parameters are not known, users of this method should
 presumably center the coordinates in some manner
 (e.g. unit standard normalization) since internally
 an identity matrix is used for K.</dd>
<dd><code>x2</code> - the image 1 set of correspondence points.  format is 3 x N where
      * N is the number of points.
      * NOTE: since intrinsic parameters are not known, users of this method should
      * presumably center the coordinates in some manner
      * (e.g. unit standard normalization) since internally
      * an identity matrix is used for K.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the top 2 solutions for the set of {estimated projections P1 and P2, and the triangulation of x1 and x2 in WCS}
 Note that if normalization was performed on x1, and x2, you may want to
 denormalize the results such as the translation column of P2 which is the last column of P2.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="solveFor4Projective(double[][],double[][],double[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>solveFor4Projective</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.MotionAndStructure.html" title="class in algorithms.imageProcessing.transform">Reconstruction.MotionAndStructure</a>[]&nbsp;solveFor4Projective&#8203;(double[][]&nbsp;x1,
                                                                      double[][]&nbsp;x2,
                                                                      double[]&nbsp;outV3)
                                                               throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">estimate the projection matrices P1 and P2 using planar homography.
 This is also called Projective Structure From Motion for the
 Two-camera case.   it's a distorted version of euclidean 3d.
 4 solutions are returned and the user should decide between them by which produces
 the larger number of points in front of the camera via triangulation of each pair of
 correspondence.

 NOTE that because the camera calibration, that is, intrinsic parameters,
 are not known, only the projective reconstruction is possible,
 but this can be upgraded to
     affine (parallelism preserved) and Euclidean (parallelism and orthogonality preserved)
     reconstructions.
     To upgrade to an affine projection, need 3 vanishing points
     (see Example 6.5 of MASKS).
     To directly upgrade from projective to euclidean projection, need
     5 ground truth points in general position, that is, no 4 points
     are coplanar (see Section 9.3 of Belongie lec 9. and MASKS chap 5 "Historical Notes" and Algorithm 11.7).

 <pre>
 following "An Invitation to 3-D Vision" by Ma,  Soatto,  Kosecká, and Sastry
 noted as MASKS.
 Algorithm 5.2 in Chapter 5 and their code homography2Motion.m from
 https://cs.gmu.edu/~kosecka/bookcode.html
 which is free for non-commercial use.
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x1</code> - the image 1 set of correspondence points.  format is 3 x N where
 N is the number of points.
 NOTE: since intrinsic parameters are not known, users of this method should
 presumably center the coordinates in some manner
 (e.g. unit standard normalization) since internally
 an identity matrix is used for K.</dd>
<dd><code>x2</code> - the image 1 set of correspondence points.  format is 3 x N where
      * N is the number of points.
      * NOTE: since intrinsic parameters are not known, users of this method should
      * presumably center the coordinates in some manner
      * (e.g. unit standard normalization) since internally
      * an identity matrix is used for K.</dd>
<dd><code>outV3</code> - is the last row of SVD(H).V where H is the homography built from x1 and x2.  it should be length 3.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the top 2 solutions for the set of {estimated projections P1 and P2, and the triangulation of x1 and x2 in WCS}
 Note that if normalization was performed on x1, and x2, you may want to
 denormalize the results such as the translation column of P2 which is the last column of P2.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateProjectiveReconstruction(double[][],int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateProjectiveReconstruction</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.ProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ProjectionResults</a>&nbsp;calculateProjectiveReconstruction&#8203;(double[][]&nbsp;x,
                                                                                 int&nbsp;mImages)
                                                                          throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOT READY FOR USE
 TODO: proof read the algorithm and write test for this.
 for the case of un-calibrated cameras viewing the same scene features,
 recover the 3-D coordinates in WCS and the projection matrices 
 from pairs of corresponding
 un-calibrated image points, that is, points in the image reference frame in pixels.
 
 The method implements the Sturm & Triggs 1996 algorithm: 
     "a method for the recovery of projective shape and motion from multiple 
     images of a scene by the factorization of a matrix containing the images 
     of all points in all views. This factorization is only possible when the
     image points are correctly scaled. The major technical contribution of 
     this paper is a practical method for the recovery of these scalings, 
     using only fundamental matrices and epipoles estimated from the image data."
     "[it is a] closed form solutions, not iterative bundle-adjustment..."
 <pre>
 references:
 
 Sturm and Triggs 1996, 
    "A Factorization Based Algorithm for Multi-Image Projective Structure and Motion"
     https://link.springer.com/content/pdf/10.1007/3-540-61123-1_183.pdf
    
    see also proj_recons_fsvd.m from http://lear.inrialpes.fr/people/triggs/src/
    which has a very liberal copyright in the file COPYRIGHT
    Copyright Bill Triggs (http://www.inrialpes.fr/movi/people/Triggs),
    INRIA (http://www.inria.fr) and CNRS (http://www.cnrs.fr),
    1995-2002. All rights reserved.

    You may use and distribute [*] this work with or without modification,
    for any purpose and without fee or royalty, subject to the following
    conditions:
       (see file COPYRIGHT)
    
 </pre>
 
 NOTE: Sturm & Triggs 1996 state in their code, "% The projective output 
     frame is numerically well-conditioned, but otherwise *completely* 
     arbitrary. It has *no* relation to any Euclidean frame.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the image coordinates of feature correspondences in 2 or more
 images.  format is 2 X (nImages * nFeatures) where row 0 holds the x-coordinates
 and row 1 holds the y-coordinates and each image's features are given
 before the next and the features are ordered in the same manner within
 all images.
 for example: row 0 = [img_0_feature_0, ... img_0_feature_n-1, ... img_m-1_feature_0,...
     img_m-1_feature_n-1].</dd>
<dd><code>mImages</code> - the number of images in x.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the estimated projections P1 and P2 and the objects locations as 3-D points;</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateUsingEssentialMatrix(double[][],double[][],double[][],double[][])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateUsingEssentialMatrix</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.ReconstructionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ReconstructionResults</a>&nbsp;calculateUsingEssentialMatrix&#8203;(double[][]&nbsp;intr1,
                                                                                 double[][]&nbsp;intr2,
                                                                                 double[][]&nbsp;x1,
                                                                                 double[][]&nbsp;x2)
                                                                          throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOTE: the method needs improvement to choose the best 2 solutions, meanwhile prefer to use
 calculateProjectiveReconstruction(double[][] x1c, double[][] x2c).
 given correspondence between two images in image coordinates calculate 
 the extrinsic camera parameters and the 3-D points.
 
 This method calculates the essential matrix and uses the SVD of it to
 extract the translation and possible rotation matrices which are
 filtered to find the best while calculating triangulation for each point.
 
 Note that the absolute translation between the two cameras can never be 
 recovered from pure image measurements alone, regardless of how many 
 cameras or points are used as ground control points are
 needed.
 <pre>
 following CMU lectures of Kris Kitani at 
     http://www.cs.cmu.edu/~16385/s17/Slides/12.5_Reconstruction.pdf
     Szeliski 2010, Chapter 7, and eqn (7.25).
     Ma, Soatto, Kosecká, and Sastry 2012, "An Invitation to 3-D Vision", pg 121 
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>intr1</code> - intrinsic camera matrix for image 1 in units of pixels.</dd>
<dd><code>intr2</code> - intrinsic camera matrix for image 2 in units of pixels.</dd>
<dd><code>x1</code> - the image 1 set of correspondence points in image reference frame.
 format is 3 x N where N is the number of points.</dd>
<dd><code>x2</code> - the image 2 set of correspondence points in image reference frame.
 format is 3 x N where N is the number of points.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateAffineReconstruction(double[][],int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateAffineReconstruction</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.OrthographicProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.OrthographicProjectionResults</a>&nbsp;calculateAffineReconstruction&#8203;(double[][]&nbsp;x,
                                                                                         int&nbsp;mImages)
                                                                                  throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOTE: not ready for use yet.
 
 TODO: proof read the algorithm and write test for this.
 for the case where the cameras are viewing small, distant scenes,
 recover the 3-D coordinates in WCS and the rotation matrices 
 from pairs of corresponding
 un-calibrated image points, that is, points in the image reference frame in pixels.
 assumes an orthographic camera model.
 can use the orthographic camera model when
    (the average distance of an object from the camera) 
     .geq. 10*(the average width of the object (measured along the optical axis of the camera).
 <pre>
 references:
 
 lecture 16 notes from Serge Belongie lectures from Computer Vision II, CSE 252B, USSD
 http://www-cse.ucsd.edu/classes/sp04/cse252b/notes/lec16/lec16.pdf
 
 lectures of Deva Ramanan at http://16720.courses.cs.cmu.edu/lec/sfm.pdf
 .:w
 
 Tomasi & Kanade 1991, "Shape and motion from image streams under 
 orthography: a factorization method", International journal of computer vision 
 
  Morita and Kanade 1997 for solving Q.
         T. Morita and T. Kanade, A Sequential Factorization Method for Recovering Shape and Motion
         from Image Streams, Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 19,
         no.8, pp.858-867, Aug 1997  (1994?)
         
 Higham, 1988, “Computing a Nearest Symmetric Positive Semidefinite Matrix,” 
    Linear Algebra and Appl., 103:103-118, 1988
 
 a great summary of the above:
 http://note.sonots.com/SciSoftware/Factorization.html#cse252b
 http://note.sonots.com/?plugin=attach&refer=SciSoftware%2FFactorization&openfile=Factorization.pdf
 
 and a derivation of the geometry of the tracking equation:
 Birchfield 1997, "Derivation of Kanade-Lucas-Tomasi Tracking Equation"
 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.185.413&rep=rep1&type=pdf
 </pre>
 NOTE: could overload this method to enable handling of occlusion 
 following Section 5 of Tomasi & Kanade 1991, but might want to alter the
 algorithm to use geometric median in place of centroid so that the
 "centers" are not as affected by removing or adding a point.
 NOTE: comments from Poelman & Kanade 1992:
 Orthographic projection does not account for the apparent change in size 
 of an object as it moves toward or away from the camera, nor the different 
 angle from which an object is viewed as it moves parallel to the image plane.
 NOTE: consider implementing Section 3.3 Sequential Factorization Algorithm
 from the Morita & Kanade 1997 paper (1994?)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the image coordinates of feature correspondences in 2 or more
 images.  format is 2 X (nImages * nFeatures) where row 0 holds the x-coordinates
 and row 1 holds the y-coordinates and each image's features are given
 before the next and the features are ordered in the same manner within
 all images.
 for example: row 0 = [img_0_feature_0, ... img_0_feature_n-1, ... img_m-1_feature_0,...
     img_m-1_feature_n-1].</dd>
<dd><code>mImages</code> - the number of images in x.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the estimated projections P1 and P2 and the objects locations as 3-D points;</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="_DoNotUseThisCalculateAffineReconstruction(double[][],int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_DoNotUseThisCalculateAffineReconstruction</h4>
<pre class="methodSignature">static&nbsp;<a href="Reconstruction.OrthographicProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.OrthographicProjectionResults</a>&nbsp;_DoNotUseThisCalculateAffineReconstruction&#8203;(double[][]&nbsp;x,
                                                                                               int&nbsp;mImages)
                                                                                        throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOT READY FOR USE.
 a look at enforcing orthonormal rotation</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - </dd>
<dd><code>mImages</code> - </dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateParaperspectiveReconstruction(double[][],int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateParaperspectiveReconstruction</h4>
<pre class="methodSignature">public static&nbsp;<a href="Reconstruction.ParaperspectiveProjectionResults.html" title="class in algorithms.imageProcessing.transform">Reconstruction.ParaperspectiveProjectionResults</a>&nbsp;calculateParaperspectiveReconstruction&#8203;(double[][]&nbsp;x,
                                                                                                     int&nbsp;mImages)
                                                                                              throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOT READY FOR USE.
 for the case where the cameras are viewing small, distant scenes,
 recover the 3-D coordinates in WCS and the projection matrices 
 from pairs of corresponding
 un-calibrated image points, that is, points in the image reference frame in pixels.
 assumes a para-perspective camera model.

 Input set of P feature point coordinates (x_f_p,y_f_p) , for each of 
 the F frames of the image sequence. From this information, our goal is 
 to recover the estimated shape of the object, given by the position 
 s_P, of every point, and the estimated motion of the
     camera, given by iHat_f, jHat_f, kHat_f for each frame in the sequence. 
     Rather than recover iHat_f in world coordinates, we generally recover 
     the three.eparate components tHat_f dot iHat_f, tHat_f dot jHat_f,
     tHat_f dot kHat_f.
 
      
     <pre>
      references:
      
     Poelman & Kanade 1997 (1994), "A Paraperspective Factorization Method for Shape 
     and Motion Recovery" 
     
     Description from Poelman & Kanade:
      
     Each feature point p that we track corresponds to a single world point, 
      located at position s. in some fixed world coordinate system.

      Each image f was taken at some specific camera orientation, which we 
      describe by the orthonormal unit vectors i_f, j_f and k_f 
      where kf_ points along the camera's line of sight, 
      i_f corresponds to the camera image plane's x-axis, 
      and j_f corresponds to the camera image's y-axis.
      
      t_f is a vector pointing from the origin of the fixed world coordinate system
      to the camera's focal plane.  it's the position of the camera in each fram f.
      
     </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the image coordinates of feature correspondences in 2 or more
 images.  format is 2 X (nImages * nFeatures) where row 0 holds the x-coordinates
 and row 1 holds the y-coordinates and each image's features are given
 before the next and the features are ordered in the same manner within
 all images.
 for example: row 0 = [img_0_feature_0, ... img_0_feature_n-1, ... img_m-1_feature_0,...
     img_m-1_feature_n-1].</dd>
<dd><code>mImages</code> - the number of images in x.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the estimated projections P1 and P2 and the objects locations as 3-D points;</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="calculateProjectiveHomographyWithLeastSquares(double[][],double[][],double[][],double[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateProjectiveHomographyWithLeastSquares</h4>
<pre class="methodSignature">public static&nbsp;double[][]&nbsp;calculateProjectiveHomographyWithLeastSquares&#8203;(double[][]&nbsp;x1P,
                                                                       double[][]&nbsp;x2P,
                                                                       double[][]&nbsp;fm,
                                                                       double[]&nbsp;e2)
                                                                throws no.uib.cipr.matrix.NotConvergedException</pre>
<div class="block">NOT READY FOR USE YET.  Looks like there's an error in the last column of the result as
 the numbers are too large.

 calculates the homography as the canonical pose for the un-calibrated camera
 (the projective projection as the 2nd image's projection
 in the canonical decomposition, pg 189 of MASKS).
 <pre>
 The homography H in [x2]_x*H*x1 = [x2]_x*( ([e2]_x)^T * F + e2*v^T)*x1 ~ 0
 where [b]_x is the skew-symmetric matrix of vector b.

 the skew symmetric matrix multiplication replaces the cross product.
 x2 cross H*x1 ~ 0.

 Details from Chapter 6 of Ma, Soatto, Kosecka,& Sastry (MASKS)
 "An Invitation to Computer Vision, From Images to Geometric Models"

 let X' = K*X and T'=K*T where K is the intrinsic camera parameters matrix.

 from euclidean transformation, we can derive the
 epipolar constraint:  x2'^T * [T']_x * K *R * K^-1 * x1' = 0

 x2^T*[T]_x*R*x1=0 <==> x2'^T * [T']_x * K *R * K^-1 * x1' = 0
    
     F = K^-T * [T]_x * R * K^-1 (when K=I, F=E)
            = [T']_x * K * R * K^-1 if det(K)=1, else it's approx (up to a scale factor)
    
    epipoles e2^T*F = 0, F*e1 = 0.
         e2 = K*T
         e1 = K*R^T*T
         
    epipolar constraint for uncalibrated cameras:
        x2'^T * [T']_x * K *R * K^-1 * x1' = x2'^T * [T']_x * (K*R*K^-1 + T'*v^T)*x1'
        = x2'^T * [T']_x * R' * x1'
           where v is an arbitrary vector
           
    since F = [T']_x * K *R * K^-1,
       fitting for the projection |(K*R*K^-1 + T'*v^T), v_4*T'|
    one can then approximate the uncalibrated camera pose.
     choosing solution  this is a 4-parameter family of ambiguous decompositions.
    pg 187 of MASKS.
    This method implements point 4 in algorithm 11.9 on pg 405, Section 11.5 of MASKS.    
 </pre></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x1P</code> - the image 1 (a.k.a. left) half of correspondence points. format is 3 x N
 where N is the number of points. NOTE: since intrinsic parameters are not
 known, users of this method should presumably center the coordinates in
 some manner (e.g. subtract the image center or centroid of points) since
 internally an identity matrix is used for K.</dd>
<dd><code>x2P</code> - the image 2 (a.k.a. right) half of correspondence points. format is 3 x N where
 N is the number of points. NOTE: since intrinsic parameters are not
 known, users of this method should presumably center the coordinates in
 some manner (e.g. subtract the image center or centroid of points).</dd>
<dd><code>fm</code> - the fundamental matrix.  size is 3X3.</dd>
<dd><code>e2</code> - the left null space in the left singular vector of F.
 it's the last column of svd(fm).u and represents the location of
 the image 1 optical center (a.k.a. camera center).
 The epipole is the point where the baseline (the line joining the two
 camera centers ol, O2) intersects the image plane in each view,
 e2^T*F=0.  e2 = K*T where T is translation vector between cameras
 (a.k.a. the extrinsic camera parameter called translation).
 (NOTE: e1=K*R^T*T where R and T are extrinsic camera rotation and translation).</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</li>
</ul>
<a id="populateWithDet1Rs(double[][],double[][],double[][],double[][],double[][])">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>populateWithDet1Rs</h4>
<pre class="methodSignature">static&nbsp;void&nbsp;populateWithDet1Rs&#8203;(double[][]&nbsp;u,
                               double[][]&nbsp;vT,
                               double[][]&nbsp;r1Out,
                               double[][]&nbsp;r2Out,
                               double[][]&nbsp;uOut)</pre>
</li>
</ul>
</li>
</ul>
</section>
</li>
</ul>
</div>
</div>
</main>
<!-- ========= END OF CLASS DATA ========= -->
<footer role="contentinfo">
<nav role="navigation">
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a id="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a id="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a id="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</nav>
</footer>
</body>
</html>
