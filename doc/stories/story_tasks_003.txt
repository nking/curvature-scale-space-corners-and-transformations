========================================================================
Story: Determine scale w/ blob perimeters and corners
 
    summary: The current implementation of scale calculation uses scale 
      space image contours of the blob perimeters to find matching 
      points and hence scale, but it is vulnerable to differences in the 
      contours between images, for example, due to a large bump or 
      occlusion.  An alternate method is needed to use the same blob 
      perimeters, but corners instead of inflection points and contours.  
      Both methods should be available for use after the changes, but 
      the new algorithm will be the default.
      (see the end of docs/contours.pdf)

    time estimate: 
        minimum: 3 days
        maximum: 2 weeks

    amount of time used: 

    state of completion: in implementation phase

    comments regarding state:

    comments:
        Refactoring of code associated with the current calculations is
        necessary before the new algorithm to assert that the 
        abstraction is correct.
        Much of the logic needed is already known from the experience
        of implementing the scale calculations with contour matching
        so the more detailed specification for Task 3 and Task 4 
        should not take long before implementation.

---------------------------------------------------------------------
Task 1:
    goal: Refactor the current BlobScaleFinder and associated classes
       to make the current algorithm available as an alternative choice,
       but the default will be the current algorithm when implemented.
      
    details:  

       BlobScaleFinder:
           should be abstracted to IBlobScaleFinder
               public TransformationParameters solveForScale(
                   ISegmentedImageHelper img1Helper, SegmentationType type1,
                   boolean useBinned1,
                   ISegmentedImageHelper img2Helper, SegmentationType type2,
                   boolean useBinned2,
                   float[] outputScaleRotTransXYStDev)
               public void setToDebug()
           with concrete implmentations:
               BlobContoursScaleFinder
                  is given all content from BlobScaleFinder
               BlobCornersScaleFinder
       
       SegmentedImageHelper:
          should be abstracted to an interface ISegmentedImageHelper, and AbstractSegmentedImageHelper
              
          ISegmentedImageHelper:
              public void applySegmentation(SegmentationType type, boolean applyToBinnedImage) 
                  throws IOException, NoSuchAlgorithmException;
              public void generatePerimeterPointsOfInterest(
                  SegmentationType type, boolean applyToBinnedImage)

          AbstractSegmentedImageHelper:
              should contain all except contour methods and members from existing SegmentedImageHelper

          SegmentedImageBlobContourHelper
          SegmentedImageBlobCornerHelper

       BlobScaleFinderWrapper:
          should be changed to use contours or corners.
          if choice is contours, SegmentedImageBlobContourHelper is constructed and BlobContoursScaleFinder is
              used, else the corner implementations.

       Adapt tests to the changes.

    time estimate: < half day
  
    amount of time used: 2 hours

    state of completion: complete

    comments:
       Later, could consider to implement the service provider interface for contour inflection
       points or corners as choices... It's not the goal of the overall project currently to 
           always provide a choice.
       see $JDK_HOME/docs/technotes/guides/jar/jar.html#Service_Provider 
              
---------------------------------------------------------------------
Task 2:
    goal: Need ability to make corners given just a curve rather than  
        an image.

    details:  
       The existing class CurvatureScaleSpaceCornerDetector should
           move the corner making portion to a separate class.
           The content that needs to be encapsulated is all
           within method 
               Map<PairIntArray, Map<SIGMA, ScaleSpaceCurve> > maps =
                   findCornersInScaleSpaceMaps(edges, useOutdoorMode, corners);

           changes in method:
              member variables need to be passed in as arguments:
                  enableJaggedLineCorrections
                  doStoreCornerRegions
                  edgeCornerRegionMap
                  factorIncreaseForCurvatureMinimum

           new class for moved method and member variable settings: 
               CSSCornerMaker

        Adapt tests to the changes.

    time estimate:  minimum couple of hours, maximum 1 day.
  
    amount of time used: 1 hour

    state of completion: complete

    comments:
              
---------------------------------------------------------------------
Task 3:
    goal: Implement the content for classes for corners specified in 
        Task 1 and add new tests for them, excepting the corner
        matching algorithm which has its own task 4.

    details:  
        Implement:
           BlobCornersScaleFinder
               public TransformationParameters solveForScale(
                   ISegmentedImageHelper img1Helper, SegmentationType type1,
                   boolean useBinned1,
                   ISegmentedImageHelper img2Helper, SegmentationType type2,
                   boolean useBinned2,
                   float[] outputScaleRotTransXYStDev)

           SegmentedImageBlobCornerHelper
               public void generatePerimeterPointsOfInterest(
                   SegmentationType type, boolean applyToBinnedImage)

       BlobScaleFinderWrapper:
          should be changed to use contours by default

       ClosedCurveCornerMatcher:    
       Implement combining the blob perimeter corner matching results
        to find the best points that should be used for the euclidean
        transformation calculation.

           (0) order the perimeters in same orientation.  contours are using
               CCW order:
                  MiscellaneousCurveHelper curveHelper = new MiscellaneousCurveHelper();
                  boolean isCW = curveHelper.curveIsOrderedClockwise(testContour);
           (1) compare each from list of blob perimeters of image 1 
               to those in image 2
               -- if the number of corners in current curve1 is very different
                  in the current curve2, log them and discard, do not try to match
               -- use ClosedCurveCornerMatcher to match the points in curve1 w/ curve2.
                  -- the results should be comparable to all other for the same
                     curve1 to find the best 2 solutions for curve1
           (2) with a map of the top 2 best solutions for each curve1, find the
               best consistent answers among the solutions.

               with the contours, was able to adjust all costs to same
               reference frame (which was the largest sigm from contour peaks). 
               Here, the cost is now distance from predicted points so should 
               be in the same frame already to compare against other curve results.

               Then the contour algorithm uses bipartite matching between the 
               curve1, curve2 pairings for the highest number of matchings for lowest cost.
           
               Then the algorithm removes solutions that have rotation very different
               from the best solution(s).

               Similar solutions to the best solution are then gathered to make the
               largest set of matched points.
               Those points are then given to the class which pairs the points and 
               solves for euclidean transformation.

        Tests are needed too.  First can use the real data while tuning the method.

    time estimate: minimum 1 day, maximum 1 week, expecting ~2 days w/ minimum testing
                   but another may be needed for changes coincident with matching algorithm.
  
    amount of time used: 
         1 hr

    state of completion:

    comments:

        When have test images that have textures of different size, may need to provide
        a way to recognize that and process the results from each curve's
        ClosedCurveCornerMatcher use for that specific (rare?) use case.
          A new task should be made for that in the future.
              
---------------------------------------------------------------------
Task 4:
    goal: Implement the blob perimeter corner matching algorithm.

    details:  
        Create new class ClosedCurveCornerMatcher.

        The class will have an algorithm similar to the Mokhtarian and
        Macworth min cost search for matching contour peaks, but 
        instead of scale space contours, it will use the closed
        curve's corners and feature descriptors.
        The algorithm here is using point location (x,y) instead of
        scale-free length. 

        The cost and penalty have to be adjusted to using SSD of feature
        instead of sigma of peak.

        The contour algorithm used as a reference, the properties of
        strongest peak in the contours of an edge.  That sigma was
        used to calculate a penalty for matches of solutions that
        start with smaller sigma contours.
           For corners and feature descriptors, the equivalent should
           be some measure of best matched singly or best matchable
             -- considering the smallest error for a feature (where 
                error is the descriptor's auto-correlation SSD).
             -- considering the corner w/ the largest curvature magnitude.
                
                  X_dot(t,o~) * Y_dot_dot(t,o~) - Y_dot(t,o~) * X_dot_dot(t,o~) 
        k(t,o~) = -------------------------------------------------------------
                                 (X_dot^2(t,o~) + Y_dot^2(t,o~))^1.5


           Then a search pattern is needed.  The following is for comparison
           of one curve's corners in image 1 to another curve's corners in
           image 2.

           (1) Find the best match by feature descriptor SSD of each corner in
               curve 1 to curve 2.
               For the first corner in curve1, that search is O(N_curves2).
               For all corner1 points, the runtime for this stage is then
                  N_curves1 * O(N_curves2).

               This is kept to use in the remaining search.

           (2) Skipping ahead to define the cost:
               When a corner in curve1 is predicted to be located at (x2, y2) in
               image2, the smallest matching SSD within a tolerance, that
               is radius of distance from (x2, y2) is the found match.
                  The cost when there is such a point is the disance
                     between the found and predicted.

                  The cost when no point is found needs to be determined.
                     If the point were in reality not truly matchable, then
                     the cost affects all attempted matches similarly, so 
                     the cost should be less than infinity (else all solutions
                     would have infinite cost).
                     The cost for non-matched cannot be 0, that is ignored,
                     because that allows solutions with fewer or no matches
                     to have better total costs.
                     -> so the cost for a non-match should be at least as
                        large as the error for the point.
                        The cost may need to have an inverse relationship with
                        that error, so that small errors produce larger costs
                        for not finding a match.
                        Also, the cost needs to be in the reference frame of 
                        the distance.
                        Therefore, the maximum error is the tolerance in distance.
                        A normalized inverse of the SSD error could be used as
                        a factor to increase the cost past the tolerance.
                        ==> the cost for a non-matching point will be the tolerance
                            radius.
                            ---> a factor that includes inverse of SSD (statistically defined)
                                 should be experimented with to see if it improves the results.
 
           (3) The min cost heap needs to be initialized with starter solutions
               from pairs of matched points applied to one further point on the
               curves 
               (pairs of points are needed to determine the euclidean transformation and the
               evaluation is use of that transformation on other points).

               Note, considering that because the curves are ordered and both are in the same
               direction, can use the properties of that (curvature scale space) to rule
               out the trial point once the first point and second point are chosen as
               the trial point must lie between or outside of both points in both curves.
               The ordering of points in a closed curve can only be used as a filter in
               this way once two reference points are made (because as stated in the story
               and the task goal, do not want to depend upon both curves being 
               same length in physical space to use more than bounds, that is, 
               their location t in scale-free-length space
               because there are differences in the curve lengths due to noise and 
               occlusion and intensity levels etc.  Task 5 addresses a solution
               using scale-free length though.).
               
               Back to the pattern of choosing the first two matching points:

               If one knew that that best SSD match of a point in curve1 to
               point in curve2 were true for at least 2 points in the curves,
               then one could use a pattern of solution starter points of
                  pt 1 = curve1[0] w/ best SSD match in curve2
                  pt 2 = curve1[1] w/ best SSD match in curve2
                  written as (pt1, pt2) for one solution starter
                             (pt1, pt3) for another solution starter
                             (pt1, pt4)  ""
                             (pt2, pt3)  ""
                             (pt2, pt4)  ""
                             (pt3, pt4)  ""
                             which is n!/(k!(n-k)!) since k is always 2, can rewrite as n*(n-1)/2.
                                 for a curve with 4 corners, the heap would have 6 solution starter nodes

                An improvement to the  n!/(k!(n-k)!) would be to try all matches just for
                the first point in the two points needed in the solution.
                    The number of starter solutions would be  n*n*(n-1)/2 
                    The chances of finding the correct solution are much higher.
                    It requires that only one point in the corners common to both curves
                    be a true match for it's best SSD match in curve 2.
                       for a curve with 4 corners, the heap would have 24 solution starter nodes

                A more thorough pattern guaranteed to find the best solution
                would try every possible combination of curve1[0] with curve2[i] and the
                same for the 2nd point, trying all combinations of pairs.
                That would be n^3*(n-1)/2 number of solutions which becomes large
                very quickly even for a small number of points and has redundant solutions
                among them.  
                       for a curve with 4 corners, the heap would have 96 solution starter nodes
               
                It looks like a limit decided by error and runtime should be chosen to
                decide between the n*(n-1)/2. starter points and the n*n*(n-1)/2. starter points.
                      for n = 5  -->  10 vs 50
                      for n = 10 -->  45 vs 450
                      for n = 15 -->  105 vs 1575
                      for n = 25 -->  300 vs 7500
                Since the corners are already high gradient in intensities, can expect that the
                feature descriptors are somewhat unique so an assumption that the best match
                is correct for at least 2 out of n is not bad for n > 10.
       
                Note, that if needed, an improvement on the minimum approach of n*(n-1)/2 would
                be a set number of best SSD matches for a point, that is the top 2 SSD matches
                are tried instead of the top 1.  The factor would be applied to both points in
                the starter points, so for top 2, would have 4 times more, which is 2 * n*(n-1).

                It looks like a good approach to the first draft would be to use the
                n*(n-1)/2 starter pattern when both curves have number of corners > 10,
                else if number of corners is <= 10, should use the n*n*(n-1)/2 pattern.

                Whichever pattern is used, the starter solution is then applied to a third
                point in curve1 and the cost is determined.
                The starter solution and the cost are used to create a node to be inserted into
                the min cost heap.  for each solution, the corners thus far used and not used
                are kept track of.

           (4) Once the heap is initialized, the solution for successive extractions of
               the min cost node are built up one corner at a time until the min cost
               node drawn has no more untried points.

               More specifically,
                  the min cost node is extracted from the heap.
                  that solution is applied to the next strongest corner not yet selected in
                  the solution.
                  the cost is determined for the found match and a new heap node is inserted
                  back into the min cost heap.

               Note that the choice of the next point should take into consideration
                  whether it is consistently between the 2 starter points in 
                  index space or outside of them in index space.

               At some point, the extracted min cost node will have no more available matches
                  to evaluate, and that node is returned as the answer.

            Note that like the contour matching code, the invoking code needs to handle reversing
            the arguments when the scale is less than one.

    time estimate: minimum one day, maximum 1 week.
  
    amount of time used: 
       2 hours

    state of completion:

    comments:
              
---------------------------------------------------------------------
Task 5:
    goal: Implement a faster, but more likely to fail for less than ideal
        curves (see end of docs/contours.pdf), blob perimeter corner 
        matching algorithm that uses the properties of curvature scale 
        space scale-free length to choose the combinations of curve1 and 
        curve2 points in roughly O(N_corners) for a curve. It uses the
        property that corners are ordered with respect to one another 
        in both curves.

    priority:
        lower than other tasks of this story

    details:  
        ClosedCurveCornerMatcher has a couple of choices of methods to
        initialize the min cost heap.
        The 2 init heap methods in Task 4 are more complete curve1 and curve2
        corner combination patterns that use (x,y) space to try to limit 
        effects of differences in the closed curves due to noise or 
        occlusion or intensity level etc.

        This would instead, make an assumption about the curves being well 
        formed and similar, hence the number of combinations for matching if 
        they have the same number of corners is O(N_corners).

        This is a quick try at a solution for ideal curves before using 
        the more detailed Task 4 algorithm upon a fail.

        Note that the quick try, to remain simple, might insist upon the
        same number of corners in both curves.  
        A method preceding use could decide that the number of corners is close
        and filter out the weakest corner in the larger number curve.

        This algorithm would be
        good at evaluating the Venturi test images blob perimeters quickly, but
        would fail for Brown & Lee 2003 test images blob perimeters and 
        perhaps for the books test image blob perimeters.  The books test 
        images are a moving camera's perspective with objects close to the
        camera and illumination close to the objects too (the images
        are already rectified) so the result is different contours for 
        objects in the 2 images and sometimes different feature descriptors 
        right outside of the contour because of projection.  NOTE however, that 
        the stable features in the books test images are the text and so 
        segmentation tailored to just the text followed by the use of this 
        algorithm would perform well, but those images are very high quality 
        and text in others is sometimes patchy so would not perform well).

        The pattern of combinations would be:
           corners1[0] paired with corners2[0] results in the remaining being
           paired similarly corners1[1] paired with corners2[1] etc.

        The second out of N patterns would be 
           corners1[0] paired with corners2[1] results in the remaining being
           paired similarly corners1[1] paired with corners2[2] etc.

           ...

         The euclidean solution and evaluation would be similar to 
            MatchedPointsTransformationCalculator, but would use outlier
            removal first:
              -- remove points w/ feature descriptor SSD larger than error
            Then during the pairings of points in  MatchedPointsTransformationCalculator,
              -- remove deviant points in pairs with rotation larger
                 than factor * standard deviation from other rotation.
         The resulting transformation is then applied to each corner.
         The cost would be similar to Task 4, that is distance from
             predicted for each point in curve2.

         The cost for "not matched" should be similar to Task 4's, that is,
             the tolerance.

         In summary, this algorithm isn't expected to succeed for all of
         the existing test images in the project, but is worth implementing
         for a fast success or fail.

         The quality for valid solutions might need to be a little higher
         than Task 4's.

    time estimate: minimum one day, maximum 2 days.
  
    amount of time used: 

    state of completion:

    comments:
              
---------------------------------------------------------------------
Task 6:
    goal: Implement for contour matching, a quick method that will succeed 
        or fail by using an O(N) runtime complexity pattern of
        ordered pairings above a sigma limit for curvature scale space contour
        peaks.  The current existing method in the project follows 
        Mokhtarian & Macworth's algorithm.  This one would differ by not 
        using the scale-free axis and sigma in cost (evaluation) and is
        meant to succeed on scale space images such as seen on 
        pg 32 of docs/contours.pdf.

    priority:
        high

    details:  
        Test images such as the books test images where the objects are
        close to the camera and the light is close to the objects
        sometimes have distinct objects useful for matching, but whose
        immediate background (that is, the area of the image immediately
        outside the curve enclosing the object) is changing because of
        perspective so those exterior feature descriptors do not match.
        For such cases, using the properties of curvature if the object's
        closed curve is curvy, is a better characteristic for matching.
 
        In the project, the existing curvature scale space matching follows
        Mokhtarian & Macworth's algorithms, which work very well for many
        objects, but for objects such as seen on pg 32 of docs/contours.pdf
        a deviation like a bump introduced from differences in segmentation
        can result in no solution if the bump is the strongest contour.
        One can see in that image, that if the strengths of the contours
        of the two largest left contours is not as important as their
        centroids in scale space (or x,y space), that a solution would have
        been found with the caveat that only an equal number of peaks above
        a limit sigma be compared.

        This algorithm is a quick attempt to solve for that case by using
        ordered pairings above a sigma limit, but discarding the sigma 
        after that.
        The cost would be similar to that in Task 5, that is, the summed 
        distances from expected (x,y) based upon the calculated transformation.
        This O(N_contour_peaks) algorithm will succeed very quickly or
        fail quickly.

        The quality requirements for it should probably be higher
        and a minimum number of matching points required for one curve's
        best matching to be compared and combined with another curve's
        best matching to produce a larger solution.

        This algorithm is expected to work well if an image has objects that 
        are convex and concave (producing strong and many contours).

        Combining the results of each curve's best matchings is expected to
        be similar to the other methods. 

         The euclidean solution and evaluation would be similar to 
            MatchedPointsTransformationCalculator, but would use outlier
            removal first:
              -- remove points w/ feature descriptor SSD larger than error
            Then during the pairings of points in  MatchedPointsTransformationCalculator,
              -- remove deviant points in pairs with rotation larger
                 than factor * standard deviation from other rotation.
         The resulting transformation is then applied to each corner.
         
         The cost for "not matched" should be similar to Task 4's, that is,
             the tolerance, but this may change.

         In summary, this algorithm isn't expected to succeed for all of
         the existing test images in the project, but is worth implementing
         for a fast success or fail.

    time estimate: minimum one day, maximum 2 days.
  
    amount of time used: 

    state of completion:

    comments:
              
---------------------------------------------------------------------
